The ethics of the Montana election experiment
---------------------------------------------

##### MACSS 30000 - Assignment 6

##### Alexander Tyan

##### 11/20/2017

*1. Assess this study using Salganik's four principles of ethical
research.*

*i. Respect for persons*

According to Salganik (2017), the principle has two parts: treating
individuals as autonomous and offering additional protections to
vulnerable persons. This is usually applied through presenting potential
study subjects with the informed consent form (i.e. “relevant
information in a comprehensible format”). The researchers have
implemented some approaches to ensure that the study respects the
subjects (potential voters), but have not done everything possible to
satisfy this principle.

It does not seem like the study considered any additional protections
for individuals with “diminished autonomy.” Though it may not be clear
who such persons may be in this study’s case, one could perhaps think of
those with mental disabilities that would hamper an individual to
understand the contents of the mailer (e.g. that this is a research
study). For instance, such individuals may be not able to seek further
information about the study through the website provided. Though perhaps
the study chose to ignore such protections as the information about such
vulnerable population groups may not have been readily available to
researchers.

In regards to treating individuals as autonomous through an informed
consent process, the study did not offer a formal consent form, instead
opting for a mailer. I presume the authors treated the mailer as a
proxy-informed consent form, since it provided information on further
study details, organizational affiliation and funding, etc (Richman
2015). The mailer did not disclose the full purpose of the study (i.e.
whether the information induces higher voter turnout), but this may have
been justified to avoid Hawthorne effects and desirability bias noise.
Additionally, the PIs have not allowed participants to opt out of the
experiment, since everyone in the mailing list received the “treatment”
(i.e. the information mailer) regardless of their wishes. However, this
may have not been any different from what a person may be exposed to
under usual living conditions, as unwanted mail is quite commonplace.
See \#4 for potential improvements on this.

However, one major omission in respecting the persons is the intentional
use of the great seal of the state, which may have confused some
participants about the official endorsement of the study (despite
small-print text stating otherwise). If the study was not affiliated
with the government of Montana, respecting persons should have led the
researchers to avoid the use of the seal because this may have been and
was interpreted as misinformation. Furthermore, this may have been
illegal under local laws (see (iv)).

*ii. Beneficence*

Beneficence is about maximizing possible benefits and minimizing
potential harm (Salganik 2017). This includes both the participants and
the social systems.

First, let us discuss potential harm. Regarding the participants, I do
not perceive any *grave* individual harm done because of the study, as
the subject matter did not involve any physical/bodily intervention or a
risk of significant emotional trauma. The worst-case scenario for a
participant was a higher chance of voting and, perhaps, voting for a
different candidate based on perceived ideological alignment. But that
would just be a more “informed” choice, since the ideological scoring by
the researchers was based on publically available funding information.
One way to criticize this aspect of the study is to presume that the
researchers assessment of the ideological scores was objectively
erroneous and/or misleading, though such an evaluation would require a
deeper methodological assessment outside of this assignment’s scope. One
other potential harm to a participant may have been being misinformed
about the role of the great seal used on the mailer (see (i)). Regarding
the social system, the study’s beneficence may at first seem more
ambiguous. This is because, in a more closely run race (which was not
the case), such intervention could be more controversial, since it could
have altered the “organic” state of the system in a tangible way, i.e.
swaying the results of an election. However, the fact that this race was
intentionally chosen for the low probability of a contested election
shows that the researchers attempted to minimize the risk of the
intervention harm to the social system they were studying.

Second, let us discuss potential benefits. In regards to participants,
the most tangible benefit, as mentioned, is a possibility of a
better-informed election choice. In regards to the social system, the
benefit is an overall higher turnout and, thus, better civic engagement
by the citizens. Another general benefit is a better scientific
understanding of how information may/should impact non-partisan races,
something that political scientists have not studied as closely as in
the case of partisan elections (Willis 2014).

So, overall, it seems that the study attempts to balance risks and
benefits, but has some potential shortcomings, though it makes some
contribution to the overall knowledge of non-partisan campaigns.

*iii. Justice*

Salganik (2017) talks about the fair distribution of risks and benefits.
The study did not treat all subjects equally in treatment distribution
(see \#3). But if we assume, for the moment, that the sample was random,
this would amount to attempting not to single out one part of the
population over others in distributing the risks and benefits discussed
under Beneficence. Under \#3, this assumption is relaxed. Also, if there
is a significant heterogeneity of treatment effects between population
groups, one could conceivably argue that the distribution of
risks/benefits is not fair to different parties. See \#2 for more
discussion on this.

*iv. Respect for law and public interest*

Salganik (2017) breaks down respect for law and public interest to
Compliance and Transparency-based Accountability. In terms of legal
compliance, the study’s use of the great seal of Montana and the mailer
contents were questionable, as determined by the Commissioner of
Political Practices of the State of Montana. In terms of
Transparency-based Accountability, this research was marred with the
controversy before the researchers had the chance to publish the results
for the discussion with the scientific community and the public. So, in
this sense, the PIs did not have the chance to go publicly transparent
with their research. However, they could have been in better
communication (i.e. more transparent) with the local campaign watchdog
authorities prior to even conducting the study. This could have
preempted the PR debacle that followed the study. Moreover, the
researchers did not submit the mailer with the seal to the IRB approval
at neither Stanford nor Dartmouth, which also seems not consistent with
the federally-regulated IRB practices (Salganik 2017).

Thus, the researchers have failed to not only respect the local law, but
also common IRB practices.

*2. Assume that the mailers were sent to a random sample of voters:
under what conditions might this mailing have altered the outcome of the
Supreme Court Justice election?*

One possible condition for such a scenario is if there is a
substantially large heterogeneity of treatment effects between different
population groups, with say a group affiliated with one party being more
prone to mobilize to vote in response to treatment than another group.
For instance, say that receiving a mailer with the ideological
information in the study tends to not mobilize Republican voters very
much, but tends to encourage voting in Democrats quite a bit, as
compared to the system without the researchers’ experiment. If the
treatment was randomized, the proportion of Republican vs Democrat
voters would be similar in the sample and the general Montana
population. But even though the treatment was randomized, if this
difference in effects between the two groups was large enough (and/or
that in the non-treatment world the race was already close enough), the
heterogeneity could potentially alter the elections results. In this
hypothetical scenario, the treatment would favor a Democratic candidate,
but one could imagine this mechanism working in either direction.
Additionally, this would be even more of a risk if the sample was quite
large, giving this effect an effectively larger broadcast over the
population. In fact, the sample was indeed quite large, at about 15% of
registered voters (Salganik 2017). In conclusion, conditions that could
alter a result would be significant heterogeneity of treatment effects,
already close-enough race, and a large enough sample exposed to
treatment.

*3. In fact, the mailers were not sent to a random sample of voters.
According to a report by Jeremy Johnson (a political scientist who
assisted in the investigation), mailers "were sent to 64,265 voters
identified as likely liberal to centrist leaning in Democratic leaning
precincts and 39,515 voters identified as conservative to centrist in
Republican leaning precincts. The researchers justified the disparity
between Democratic and Republican numbers on grounds that they
anticipated turnout to be significantly lower among Democratic voters."
Does this change your assessment of the research design? If so, how?*

Yes, as discussed in under \#1, (iii), researchers should consider
Justice as one of the ethical principles. Salganik (2017) argues that
when considering fair distribution of risks and benefits, researchers
are to think about not only the participants, but the systems more
generally. In this scenario, where researchers are intervening in a way
that is understandably designed to enhance the research results, they
are also consciously altering the organic state of the system in way
that potentially mobilizes Democrat voters more than Republican ones
because the Democrat sample is unrepresentatively larger than the
Republican sample. In such a scenario one could argue that the study
does not satisfy the Beneficence and Justice principles of ethical
research. Though, if one refers to \#2, we can see that either way,
doing random or not random sampling, may pose risks for altering the
system in a potentially politically controversial way. In other words,
there is no easy way to predict the future and foresee all risks.

*4. In response to the investigation, the researchers said that they
picked this election in part because "neither judicial race had been
closely contested in the primary. Based on an analysis of the 2014
primary election results in the context of previous Montana judicial
elections, the researchers determined that the research study as
designed would not change the outcome of either contest." Does this
change your assessment of the research? If so, how?*

Generally, no, because the principles that are important to consider in
\#1, \#2, and \#3 are still crucial to conducting an ethical study
regardless of anticipated results (forecasts can be wrong, after all).
However, such a defensive argument is a fallback for potentially
controversial scenarios in \#2 and \#3, so it gives the researchers a
partial justification in case these scenarios take place. However, this
still does not resolve other ethical issues, such as the ones in the
legal and individual respect realms with using an (misleading) official
government seal.

*5. In fact, the election turned out to be not particularly close. Does
this change your assessment of the research? If so, how?*

No, as outlined in \#4, this justifies some of the shortcomings of the
research design in terms of ethics, but does not resolve all of the
issues.

*6. One of the principal investigators for the Montana election study
(Adam Bonica) is also the co-founder of CrowdPAC, a for-profit company
which "calculates objective scores for political candidates showing
their overall political position" using, in part, the same data used to
score the judicial candidates in Montana. While a source of objective
information for voters to make decisions about candidates, CrowdPAC also
provides tools to organize activist communities and fund political
campaigns (all for a fee). Does this change your assessment of the
research? If so, how?*

No, because my assessment is independent of how such “objective” scoring
mechanisms may be “weaponized” in other contexts. Information or tools
can be ethically neutral and their ethical evaluation would depend on
the context in which they are used. In the context of the study, the
information was used to advance general knowledge about non-partisan
elections, with all of the ethical assessment above unrelated to how one
may use this technology of evaluating a candidate’s political ideology
in other contexts. (Though of course one could include the assessment of
this scoring method’s potential shortcomings in “objective” evaluation
of political stance and all of the resulting ethical considerations as
well. See \#1, ii). For instance, just because nuclear technology can be
used to harm millions does not have anyone advocating to ban the use of
nuclear technology in radiology medicine that benefits many patients.
Similarly in this case, to change my assessment at this point would be
rationally and ethically inconsistent.

*7. What, if anything, would you have done differently if you were the
principal investigators? How would you have designed the study if you
were interested in exploring whether additional information increases
voter turnout in nonpartisan races?*

Based on the previous analysis, several suggestions could be
implemented. First, to improve the respect for persons, on can implement
a recruitment stage for this study, where the participants are informed
more formally and thoroughly of the study’s risks and benefits and have
a chance to sign an official consent. This could be done without
disclosing all of the study’s intent, as letting participants know that
the voter turnout is the subject of interest may introduce desirability
bias into their behavior. Such recruitment procedure can also be used as
a screening mechanism to more formally identify vulnerable population
groups to exclude them from the study or apply additional protection
measures. Identifying vulnerable groups is something that the study did
not seem to consider. However, one would have to consider potential
additional costs to implement this proposed research stage, as it may
put the total study costs out of the budget’s reach.

Second, of course a more rigorous IRB procedure would need to be
followed. How did this study see the light of day when the mailer, the
main subject of controversy, was never approved by the IRB? It is a
mystery and shows that much is to be improved in terms of researchers
having more disciplined integrity to follow the IRB procedures.

Third, one commonplace mistake for researchers getting into PR debacles
seems to be a lack of contextual and situational awareness. In this
case, it seemed to be a lack of knowledge of local legal intricacies in
conducting political campaigns and a general lack of anticipation of how
Public Relations work. Thus, one modification would be to consider
additional legal and PR advice. It may be hard to know what these
intricacies may be across many jurisdictions, but this study seems
localized enough that the researchers could have given this greater
consideration. It is no wonder that Dartmouth intended to add a legal
adviser to their IRB board after this incident (Richman 2015). This
practice should become commonplace, along with PR advising in studies
that merit such preparation and such prior consultation would be one
change I would implement. Additionally, as noted before one could have a
better established communication line with the appropriate electoral
watchdog institutions prior to conducting the study to minimize the risk
getting into trouble with the public.

Fourth, it is unclear why the sample size was so large. What is more
clear is that, if possible methodologically, the study could have used a
smaller sample to minimize any publish backlash that has occurred.
Indeed, covering 15% of the electorate with the treatment is quite large
(and resource-intensive). Therefore, in my design I would consider
investigating whether one could do with a smaller sample size.

Bibliography

Richman, Josh. 2015. “Stanford and Dartmouth Researchers Broke Law with
Election Mailer, Montana Official Says.” The Mercury News (blog). May
12, 2015.
<http://www.mercurynews.com/2015/05/12/stanford-and-dartmouth-researchers-broke-law-with-election-mailer-montana-official-says/>.

Salganik, Matthew J. 2017. Bit by Bit: Social Research in the Digital
Age. Princeton, NJ: Princeton University Press.

Willis, Derek. 2014. “Professors’ Research Project Stirs Political
Outrage in Montana.” The New York Times, October 28, 2014, sec. The
Upshot.
<https://www.nytimes.com/2014/10/29/upshot/professors-research-project-stirs-political-outrage-in-montana.html>.
