# Evaluating Research Designs
 
Xiuyuan Zhang


## Section 1: On *Digital Discrimination: The Case of Airbnb.com* (2014)
### Summary of the Research Design
In this study done by B. Edelman and M. Luca in between 2012 and 2014, they examined the existence of digital discrimination in the specific form of racial discrimination and further explored the correlation between racial discrimination and listing prices of properties on Airbnb.com. In this observational study, researchers collected data on all New York City landlords' profile photos, listing price, qualities of the property and other characteristics of the property(including features like location and num of bedrooms) as of July 12, 2012. The coding of the racial identity of landlords based on their profile picture as well as ratings of the quality of a given property based on given photos of the property are performed by third-party workers online. This study has shown that, compared to non-black hosts, black hosts charge 12 percent less for a property, taking into consideration the control of other potential confounding factors. This result suggests that the presence of profile pictures on Airbnb.com has left black hosts to experience racial discrimination.

### Discussion on the Study and Computational Methods
This observational study has taken advantage of the new digital age and computational methods. In addition to the initial stage of collecting data from Airbnb.com using snapshots of different listings, this study also took advantage of mass collaboration. As mentioned in the previous paragraph, this study delegated the task of coding the race of Airbnb hosts and rating the quality of properties to third-party workers from Amazon Mechanical Turk.

### Discussion on the Effectiveness of the Paper
**i. Characteristics of the Big-Data Digital Research, Heterogeneity and this Study**

In his book *Bit by Bit*, M. Salganik mentioned ten characteristics of big data research. B. Edelman and M. Luca's research took advantage of several of these characteristics: big, always-on, and non-reactive. However, this study also shows potential drawbacks since it risks having the desired data being non-representative or not accessible.

Since B. Edelman and M. Luca have collected data on all New York City Airbnb hosts, the data size is big. This bigness of the data gives researchers a large population to study. It allows researchers to find heterogeneity in the data, first between black and non-black hosts, and further identifying the potential confounding factors such as influences of the property's location, posted pictures of the property, or whether guests would have to share the property with others and how many other guests do they have to share the property with. However, if the data size were small, it would be difficult for researchers to identify these confounding factors and any possible heterogeneity within the data, and further challenges the construct validity of the study. Moreover, since the data on Airbnb is always-on and the information on hosts and information of properties are up to date, researchers are able to collect information that truthfully reflect what any Airbnb visitor on July 12, 2012 would see. Although the study itself is not longitudinal, it collects data that resulted from a longitudinal process, which the researchers mentioned as the reputation system of Airbnb. This allows the researchers to study the correlation between the host's profile picture and the listing price of their properties in a non-superficial way. Furthermore, since the data collected from Airbnb.com has a non-reactive nature, it supports researchers' research design for an observational study. This non-reactive aspect of the data creates an environment for researchers to observe natural and undisturbed behaviors of their subjects.  

While this study on racial discrimination has revealed to its audience a strong correlation between host's racial identity and the listing price of the host's property, its possible limitation includes 1) the collected data being non-representative and 2)the data from Airbnb is not fully accessible. First, the researcher has chosen to run their observational study for hosts in New York City. While this dataset itself is large and has several advantages mentioned in the previous paragraph, this dataset is non-representative of hosts of Airbnb.com as a whole. Moreover, there is no randomization performed when sampling the entire population. Thus the result from this study lacks certain degree of representativeness as well as external validity. Secondly, this study only included the data from hosts' profile pictures and the listing price of properties in public since Airbnb.com chose to not work with the researchers on this study. Due to the limited access, researchers were unable to access the consumer demands data, which makes this study only covers the hosts' listing prices and lacks consideration on the part of the consumer and unable to build a correlation between the racial discrimination of hosts and the consumer demands.

**ii. Validity of the Study**

Aside from the lack of consumer demands data, the construct validity of this study is relatively strong. As an abstract construct in itself, racial discrimination is observed and measured using two main operationalized variables, while taking into consideration of other possible confounding variables. The independent variable of interest is the racial identity of hosts based on profile pictures they provide, and the dependent variable is the listing price of the host' property. It is shown clearly through B. Edelman and M. Luca's study that the difference in listing price is reflective of the racial differences of hosts. Being a black host on Airbnb negatively influence the listing price of the host's property. 

The study took into consideration of possible confounding factors and performed regression on these variables together. As B. Edelman and M. Luca addressed in the paper, the effect of the confounding factors are included in their analysis, and one can still observe a comparable difference between the listing prices for black hosts and non-black hosts. By controlling for the confounding factors, researchers maintain a strong internal validity for this study, since the effect observed in the study is due to the manipulation of the independent variable and not other factors. 

Moreover, the study also has a relatively strong external validity since the findings from this study produce a similar outcome as the study done by other researchers(Fradkin 2015) prior to the B. Edelman and M. Luca's 2014 study and is occurring in a natural setting. Yet, one factor to consider is the non-representative aspect of the data, since the data is only representative of a specific city in the United States while there are many other cities and countries as well as other potentially dissimilar population on Airbnb. 

**iii. Identifying the Underlying Causal Mechanism**

Lastly, it is difficult for researchers to identify the mechanism behind the apparent correlation they have revealed using the current data. In this study, although the racial discrimination is set to be between hosts and their earnings (which depends on guests), it inevitably also involved an implied discrimination between the host and themselves, since the listing price is decided largely by the host (and the guest pays the price that the host decides on). Thus, there are potentially many intermediate steps in which guests' racial discriminations have influenced the market demands and in turn influenced the decision making of hosts when naming a listing price for their properties. It is possible also that an African American host has implicit racial discrimination against their own race but this study by itself is insufficient to show those intricate steps or possibilities. Furthermore, the researchers mention two competing models - statistical and taste-based - models to unentangle the discrimination, but they also admit that the study they performed is insufficient to give the models a good test.

Overall this study is effective in informing the scientific literature about a robust presence of racial discrimination in online market place since it  reveals a clear correlation between the variables of their interests, but it also has some limitations due to the nature of big data mentioned above and the complexity to understand underlying mechanisms. 

## Section 2: On *Racial Discrimination in the Sharing Economy: Evidence from a Field Experiment* (2017)

### Summary of the Research Design
B. Edelman et al. conducted a digital field experiment on the topic of racial discrimination and its effect on Airbnb guests in 2015. The independent variable is the racial identity of the guest and the dependent variable is the positive response rate of the host. Sampling vacant listings from different hosts on Airbnb from five major metropolitan cities in the United States, the population size of this experiment is about 6392. This experiment uses between subject design. This randomized control experiment has their participants randomly assigned to four different treatment groups: 1) African American female, 2)African American male, 3)white male, and 4)white female. The treatments are delivered by emails: hosts in the respective treatment groups receive inquiry emails that differ only in the names of potential guest. These names are tested to be indicative of the guest's racial identity and gender identity. The researchers hired third-party workers online to identify the race and gender of hosts based on their profile picture and, on a separate task, to identify the gender/racial identity of the 20 guests names researchers used to sign inquiry messages. 

B. Edelman et al. then analyzed their results and found a clear impact of race on the likelihood of acceptance by a host: African American guests(treatment groups 1 and 2) receive a positive response from the host 42% of the time, comparing to white guests(treatment groups 3 and 4)' 50% positive response rate. The hosts discriminate against both genders of African American guests even when the researchers compare across 1)different genders of hosts, 2)different races of hosts, 3) locations of the listing, 4)prices of the listing, 5)hosts' experience, and 6) whether hosts' have to share the property with guests, respectively. 

However, when examining whether hosts of different race and genders(Africa American male, African American female, white male, and white female) would discriminate against guests of different races and genders, B. Edelman et al. find that African American female hosts have a homophily for African American female guests. Moreover, using hosts' recent reviews by African American guests to filter hosts that have had African American guests and those that haven't recently, B. Edelman et al. find that the discrimination disappears for hosts who have had African American guests. Thus, this analysis tells readers that racial discrimination is concentrated among a subset of hosts rather than prevalence for all hosts unequivocally. Through examining the vacancy of property listings of hosts who gave a negative response and calculating the cost of rejecting an African American guest using their model, the researcher find that the cost of rejection is rather substantial: $65 - 100. 

The study as whole has shown that there is a robust racial discrimination against guests with African names on Airbnb.com.

### Discussion on the Study and Computational Methods
B. Edelman et al. employs the method of digital field experiment, using digital infrastructure to increase the size of their participants(6392 hosts) and the diversity of geographical location of hosts(five different cities) with little cost, randomly assign treatments to participants, deliver the respective treatment to four groups using web browser automation tools, and used hosts' online response to measure the outcomes. Further, B. Edelman et al. were able to store pre-treatment information on their participants using their own scrappers, which allows them to study the heterogeneity among participants with different backgrounds. This study also uses Face++, a face-detection API to categorize past guests' race, gender and age. 

Moreover, this study recruited Amazon Mechanical Turk workers to perform tasks on coding the gender and race of the hosts given a profile picture as well as identifying race and also in complement to the face-detection API, as well as identify gender from a given potential guest name. This is a use of mass collaboration.

However, employing these methods and run the study has created fake accounts and directed fake inquiries to hosts that may have Airbnb hosting as their main financial income, it thus raises some ethical concerns. This will be discussed in detail in the next section.

### Discussion on the Effectiveness of the Study
**i. Characteristics of Big-Data Digital Research, Heterogeneity and this Study**
This study by B. Edelman et al. on identifying racial discrimination against guests has a large population size with a relatively representative sample of participants of different races, genders, geographical locations and having different listing conditions for renting their property. Since this study wants to control for many potential confounding factors, a large dataset is needed. Moreover, the bigness of the population allows the researchers to identify heterogeneity among participants even within each treatment groups using information on these participants collected pre-treatment. It gives researchers the opportunity to have enough participants in each desired category that they would want to analyze. Furthermore, the large size of the data allows researchers to study small differences, especially if these differences are the heterogeneity that they are looking for. For instance, the difference between the rate of positive responses for African American guests and white guests is single digit even with a total of 6392 listings. One can imagine that if the population size is small, one may not be able to find a meaningful distinction.

However, since this research is done using Airbnb's database, it limits the researchers access to the data. As B. Edelman et al. mentioned in their article, their initial plan was to conduct this study over 20 different cities but they ceased after 5 cities once Airbnb blocked their automated tools to login into Airbnb guest accounts. 

**ii. Validity of the Study**
In this study, the racial difference is manifested through names of guests, and the discrimination is operationalized to be the positive response rate from hosts based on names of guests. The theoretical construct and the data gathered match and ensures construct validity of this experiment.

The internal validity of this experiment is mostly strong. First, it has carefully collected pre-treatment information on participants, with a processing by MTurk workers that reduces possible errors made by individual workers. Secondly, B. Edelman et al. have analyzed the main effects of different treatment groups with consideration of confounding factors, such as the gender of hosts/guests, the price of listings, and location of listings, etc. The result, as mentioned in the section on research design, is still prevalent and supports a correlation between racial identity of the guests and positive response rate from the guest. Nevertheless, one possible uncontrolled factor might challenge the internal validity of this experiment. As mentioned by the authors themselves, although the names of guests are distinct in race and gender, it is not controlled for these names to be from the same socioeconomic status, which may complicate the judgement and decision of hosts.

Another limitation of this study that the author addresses is that they did not observe the effect of past reviews on discrimination. Based on their calculation and comparison with data collected by other previous research, they believe that this effect is unlikely to eliminate discrimination. However, it could also potentially challenge the internal validity of this experiment.

While this experiment does not explicitly state a control group, since there are four different treatments, they can serve as control groups for each other, and ensures a fair comparison. For instance, the lack of fair comparison would occur if researchers only know the rate in which African American guests receive a positive response without knowing the rate in which white guests receive a positive response. In that case, a rate by itself lacks the power of revealing a fair comparison. On the other hand, this study done by B. Edelman solves the question of fair comparison by providing four different treatment groups. Yet, there is still one limitation on their effort to create a fair comparison, which B. Edelman et al. addressed in their paper: the names that they chose for African American guests and white guests may suggest different socioeconomic status that is not controlled for in this study.

Since it is a field experiment, it has more representative groups of hosts across different races, genders and from different cities. This study allows B. Edelman et al. to deliver their treatment in a natural settings and record their participants' natural behavior. Thus it has a relatively strong degree of external validity. However, it is worth noting that this study is so far only conducted in the U.S, and it should have more location and population validity by sampling participants from different cities and countries besides the U.S in the future. 

Moreover, the external validity of this study is reinforced by researchers showing that there is a subset of hosts(hosts who didn't have recent reviews from African American guests) exhibits discrimination against perspective American guests. This suggests that the correlation between racial identity and positive response rate is strongly related. Also, despite not having pictures, the researchers have shown that their positive response rate for perspective guests is similar to data collected by other researchers.

**iii. Identifying the Underlying Causal Mechanism (Limitation)**
This study does not provide sufficient information for one to identify the underlying mechanisms behind the decision making process of hosts' racial discrimination. It address the problems two existing theories - statistical discrimination or taste-based discrimination - respectively face when confronted with the data from this study, but cannot give further clarification on the decision-making process itself. 

**iv. Ethical Concerns**
This study raises some ethical concerns. Different from observational study where the violation may be of a concern of privacy, the first concern here is that the researchers did not obtain consent of the hosts whom they have recruited as their participants. Secondly, these fake guests inquiry about a spot in the host's property with no intention of staying. The hosts who response positively with "Yes" risks potentially losing lawful financial gain because of this study. Despite not making the official booking, if the host has held the property for the fake guest, and during which period the host rejected another inquiry from a real guest, it would be a negative consequence that the researcher inflicted on the host of Airbnb. This ethical concern, though addressed by the authors by saying that they sent the hosts a response saying that they are still looking, is still a limitation on the study. It stops this study from running on a larger scale or respectfully treating participants as autonomous persons.

This experiment is overall effective, with a potential to increase its population validity and location validity by sampling within the whole Airbnb database, its internal validity by controlling for guests names that suggest similar socioeconomic statuses. Researchers should also address the ethical concerns that surround this study. 

## Section 3: Discussion on the Two Papers

These two studies provide the scientific literature two different perspectives into the same question of racial discrimination on the online marketplace environment. The observational study examines and identifies the racial discrimination that hosts on Airbnb experience. Chronologically speaking, this study motivates B. Edelman and M. Luca to conduct a further study on the subject of racial discrimination where they can study the decision of hosts on racial discrimination against guests. The field experiment explores the racial discrimination guests experience on Airbnb because of the hosts' decision. While as mentioned above in section 1 there are limitation to the observational study, it provides researchers an angle to understand racial discrimination without making assumptions that only guests of Airbnb would experience racial discrimination. Thus, these two studies, and more broadly the two research method, complement each other well in these context. 

The nature of an observational study is inherently non-reactive, which allows researchers to record the phenomena and participants' behaviors in an undisturbed way. Considering the infrastructure of Airbnb, it is more cost-efficient for researchers to study racial discrimination against hosts through observational study than a field experiment, which would be more difficult to design and the treatments to deliver are not straightforward. On the other hand, the characteristic of a field experiment is to deliver treatments to participants in a natural setting, which serves the purpose for testing guests' experience of racial discrimination. Using made-up guests, researchers can test the hosts discrimination against said guests, while, if one were to use made-up hosts, one would have to go through more steps to create listings of properties, take pictures, wait for longer time for guests to reach out to have enough data, and, most importantly, this might have even greater ethical consequences. Each of these two study methods has served appropriately for the purpose of the study and the desired population that they want to reach. 

The shortcomings of both research are not largely due to the type of studies they chose, but rather non-representativeness, inaccessibility of the data, or the determination of causal mechanisms, which is inherently difficult for social science research to answer.

## Section 4: Apply a Digital Survey-based Research Design

As it is seen from the discussion in the previous four sections, this study that focuses on racial discrimination on the online marketplace can be well-implemented and examined using field experiment design and observational research design. The non-reactive nature of observational study and the tactful delivery of treatments of the field experiment in the previous two studies allows researchers to observe human participants' truthful response to possible chance of racial discrimination. However, it is challenging to design a survey-based research surrounding the same question of interest. Since the idea of racial discrimination is commonly recognized as a negative judgment on one's character, it is difficult to gather people's honest answer on whether they think they would racially discriminate against another person. Moreover, it is possible that the person who participate in racial discrimination on the platform does not recognize themselves to be performing a racial discriminative act. Such biases against race might be implicit. 

Accordingly, if this study on racial discrimination were to take a digital survey-based research approach, it has to overcome the problem of potential dishonesty from participants who are afraid to identify themselves as racists, or honest responses where the participants are not aware of the racial discriminative nature of their actions. One way to work around this problem is to not directly ask participants questions such as "If you are a host on Airbnb, will you accept an African American guest?" or "if you are a guest on Airbnb, will you choose an African American host?" It is apparent that these questions prone the participants to answer in a "correct" non-discriminative way and are not useful to the study. Thus, the digital survey would instead take the following form: the participants will be directed into a page that tells them:

* "Today you are helping your two friends to manage their Airbnb properties, on the next couple pages you will be presented with some guests that send you a request to rent a property, and you will click on the 10 guests on each page that you want to rent the properties to."

Then on the next three pages, they will be shown 30 profiles of people each page, and 90 profiles in total. These profiles include a profile picture of the guest applicant, and their name. On each page, there will be 15 profile pictures with names that are African American, and the other 15 white applicants' pictures and names. These names will be controlled for using supplement previous research so that they represent people from the same socioeconomic status. The pictures provided of these people will also be examined to have similar attractiveness as well as an equal female to male ratio. These will be presented in a random arrangement with no specific pattern. The participant of this survey will click on the ten guests on each page that they accept. 

While the above mentioned case tests the bias hosts may have against guests in an online market renting scenario, one can also conduct a similar research on guests' attitude on hosts. First, one will implement a code to have unrepeated MTurk workers to take this survey to avoid any MTurk worker from participating in the study twice. These groups of participants will be given the following prompt:

* "Today you are looking at places you will want to stay at for a couple days for a long weekend next month, on the next several pages, you will see some listings of properties, click on 10 potential properties that you think you would want to stay at."

Then on the next three pages, the participants will be shown 30 listings per page, 90 listings in total. Each listing include some pictures of the property as well as a short description of the place's location and its rating, and a photo of the host. Similar to the previous survey, this survey will control for the photo of hosts in the same way, and also control for the ratings and descriptions (to be very similar.)

This two surveys can be conducted through Amazon Mechanical Turk, and recruit about 200 workers per survey to start. Workers will be asked to choose their age range, race and gender if they are comfortable with providing these information. These information later can be used to analyze any potential heterogeneity within the data as well as to weight the statistical analysis. One would look at whether Mturk workers individually choose more white guests/hosts than African American guests/hosts as well as whether they collectively have a strong preference over white guests/hosts than African American guests/hosts. Furthermore, one can control for the race and gender of MTurk workers based on the information that they provide to analyze any potential heterogeneity in the study. 

If there is a strong correlation between the count chosen by participants of the survey and racial identity of the given hosts/guests, it suggests the presence of racial discrimination on online market places and calls for further field experiments and observational studies that look at the occurrences of such discriminations in real-life online market places. This survey study only addresses the question of racial discrimination on online market places to a certain degree even if there is a prevalent result from the above survey. The main limitation comes from the fact that this survey is conducted based on an imaginary scenario rather than in real life. However, since from the previous studies done by B. Edelman et al., it seems difficult to ask these surveys through Airbnb. But in that case, the scenario would still be imaginary but the participants might be more representative of the population of the online marketplace than MTurk workers. 


## Reference
1. Edelman, B. G., & Luca, M. (2014). Digital discrimination: The case of airbnb.com. *Harvard Business School NOM Unit Working Paper*, (14-054).
2. Edelman, B., Luca, M., & Svirsky, D. (2017). Racial discrimination in the sharing economy: Evidence from a field experiment. *American Economic Journal: Applied Economics*, 9(2), 1-22.
3. Salganik, Matthew J. *"Bit by Bit." Bit by Bit: Social Research in the Digital Age.* Accessed December 6, 2017. http://www.bitbybitbook.com/.








