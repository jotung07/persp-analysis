## Ethics

### Assess this study using Salganik's four principles of ethical research.
#### Respect for persons
The Montana election study did not ask for informed consent from all of the people the researchers sent mailings to. On one hand, this is a monumental task and seems impossible – it is unclear who will actually see or read the the mailings at each address, and there is not an effective way to survey a population that is not clearly defined.
Informed consent could have skewed the results of the experiment if subjects were given too much information about what sort of material to which they would be exposed. Salganik explains this problem with the example of the Emotional Contagion study; informing participants that they would be a part of an experiment on emotion could provide biased data – participants might be inclined to act a certain way (Salganik 6.6.1). 

#### Beneficence
I have several concerns about the risks involved in this particular experiment, especially in terms of whether they outweigh the benefits. First, I would want to know why this election and scale was chosen. Has the experiment been performed on local elections? The size of the experiment deepens the potential impact – flyers were sent to [roughly 1 in 6](https://sos.mt.gov/elections/voter_turnout_) registered Montata voters. Any potential tampering with state-wide election carries risks not only for the citizens thereof, but also potentially for the country at large.
Second, I think adverse risk was introduced when the researchers used obfuscating language to name their mailer, along with a reproduction of the Montana state seal. These were much more misleading than intended because voters could think that this was official government correspondence, and be moved to act a certain way because of that. The researchers also provided “information” in the form of partisan positioning, which could catalyse voters who have strong party affiliations. I would have proposed the researchers mitigate risk by choosing a different method – specifically listing donors for each candidate, and not drawing comparisons to parties or presidential candidates. Since the partisan positioning was based on donors, I would want to know how the researchers effectively calibrated President Obama and Governor Romney – did they share donors? What was the process?

#### Justice
Analyzing this experiment through the lens of justice also brings in risk mitigation from beneficence. How were vulnerable populations accounted for? Was anyone filtered out? Was it possible that the mailers were sent to areas with only a specific political or racial makeup? The study can be said to be pursued for the greater good of democracy, by finding out whether information can help raise voter turnout. However, depending on what they are, outcomes from the research might also lead to unethical activities by organizations who want to target voters and sway their opinions on elections. Granted, this is a large part of campaigning, but if researchers unearthed an extremely reliable method for increasing voter turnout based on specific types of information, that could be exploited.

#### Respect for law and public interest
This is the pillar that I see the Montana study disregarding the most. By including the state seal on Montana on the mailers, the researchers were portraying themselves as the government, whether or not that was their intention. Early communication and collaboration with the state government could have given the researchers a clearer ethical course, because the state is tasked with advocating on behalf of its citizens. As Salganik says earlier, it can be useful to have a non-researcher on IRB committees in order to provide a different perspective (6.4.2). While it is possible that collaborating with the state government has its own risks – for example, being banned from performing the experiment – it would have anticipated legal and ethical questions before the execution of the study.

### Assume that the mailers were sent to a random sample of voters: under what conditions might this mailing have altered the outcome of the Supreme Court Justice election?
Ideally, if the mailers were sent perfectly randomly, the outcome of the election would remain the same; there would just be higher voter turnout. There is the possibility that the vote breakdown could have shifted, but it would not have been significant enough to completely change the outcome.

### In fact, the mailers were not sent to a random sample of voters. According to a report by Jeremy Johnson (a political scientists who assisted in the investigation), mailers "were sent to 64,265 voters identified as likely liberal to centrist leaning in Democratic leaning precincts and 39,515 voters identified as conservative to centrist in Republican leaning precincts. The researchers justified the disparity between Democratic and Republican numbers on grounds that they anticipated turnout to be significantly lower among Democratic voters." Does this change your assessment of the research design? If so, how?
The justification the researchers put forth for who they sent the mailers to does not convince me. It is possible that one of those parties is more volatile than the other – maybe Democrats in a Red state would be more likely to vote if they knew which candidate aligned with their party. Overall, I still stand by my earlier statement that the information provided should not have assigned candidates to a partisan spectrum. Ideally, the information would be presented without that layer of politics, as many people do default to their party’s candidate. What would have been more interesting (and ethical) would have been providing voters with a list of donors to each candidate, and having the voters interpret that for themselves.

### In response to the investigation, the researchers said that they picked this election in part because "neither judicial race had been closely contested in the primary. Based on an analysis of the 2014 primary election results in the context of previous Montana judicial elections, the researchers determined that the research study as designed would not change the outcome of either contest." Does this change your assessment of the research? If so, how?
This shows me that the researchers did uphold the pillar of beneficence, as they made sure there was a low risk to the population based on their experimental intervention. 

### In fact, the election was not very close. Does this change your assessment of the research? If so, how?
This shows me that the researchers did acknowledge the risk involved with a state-level election, and attempted to choose a particular election in a particular state where even a moderate intervention would not change the outcome. This does show responsibility and commitment to the pillar of justice, in looking out for the common good.

### One of the principal investigators for the Montana election study (Adam Bonica) is also the co-founder of CrowdPAC, a for-profit company which "calculates objective scores for political candidates showing their overall political position" using, in part, the same data used to score the judicial candidates in Montana. While a source of objective information for voters to make decisions about candidates, CrowdPAC also provides tools to organize activist communities and fund political campaigns (all for a fee). Does this change your assessment of the research? If so, how?
This relates to my previous point about this research potentially being used for nefarious purposes. However, turning research into a profitable product is not necessarily evil. I would want to know more about the relationship between the research project and CrowdPAC – how were funds obtained? Is Montana a target market, or does CrowdPAC have any conflicting clientele interests in the area, or related to the candidates? 
This new information alone doesn’t sway my assessment of the study, but I have significantly more questions – including whether the interests of CrowdPAC were related to a lack of collaboration with public servants.

### What, if anything, would you have done differently if you were the principal investigators? How would you have designed the study if you were interested in exploring whether additional information increases voter turnout in nonpartisan races?
There are two main changes that I would implement if I were a co-PI on this study. First, I would more clearly define what “additional information” is, and I personally would not define it to be “a partisan assignment.” I would not include comparisons to other political candidates because of the uncontrollable emotion those associations could cause. 
Second, I would seek the advice of lawyers and public policy colleagues fluent election law to see where these sorts of mailers would be legal to send, and whether the research team would need to register with the state. Once a state and election is picked – I approve of the way the researchers chose the specific election – I would approach the local government with an outline of our experiment, informing them so they can appropriately field any calls from concerned citizens. 
