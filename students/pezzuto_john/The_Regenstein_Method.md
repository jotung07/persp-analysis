The Regenstein Method
================
John-Henry Pezzuto
10/13/2017

    The University of Chicago boasts itself as the 10th largest research library in North America with over 11.6 million volumes in print and electronic form. Indeed, as a student at the university, I can substantiate that the library collection is impressive. However, it is not clear if the space holding the collection is being managed as well and as efficiently as it could be. Having 11.6 million different books may not be better than having 11.6 million books with multiple copies of some especially popular books. It is likely that most books in the library’s collection progressively deteriorate over the years, and are seldom checked out by students -- but some other books (i.e. longtime international best sellers like Harry Potter) simply are not available to students because of high demand. Currently the library system has specialist librarians in charge of purchasing books but as far as I can tell no quantitative approach has yet been tried to manage availability. Under these assumptions, I propose that the library system attempts to raise its efficiency by forecasting the demand for currently popular books by counting relevant book demand measures.
    Gathering a source of data for this project is very feasible. Nearly all modern libraries, including ours, have online databases of books reflecting current availability. As is the reputation of librarians to keep meticulous records, historical records of this data should be also be readily available. Relevant data related to user book demand, such as how often the book is “recalled” from other students, how often a book is “checked out”, how many students keep this book on a “reading list”, and most importantly how long the book remains idle between “check out sessions”, would give very clear metrics defining the demand of a book. In the cases where there is a historically high demand for a book, and which no copies of a book ever remain idle, it is likely the library does not have enough copies of the book on hand and may need to purchase more, shorten the lending period, or perhaps borrow copies from another library.
    This project fits remarkably well into the standards of big data, and most importantly avoids many, if not all, of the pitfalls of big data. First, we will look at the advantages of big data offered by this project. Library patrons expect their personal library records to remain anonymous, but rarely worry about how the library decides to purchase new books. So long as library records remain anonymous, current library patrons will not change their behaviors in the way that they check out books, making this nonreactive data. It is possible that increased availability of books will cause more students to use the library (rather than purchase their own copies of the book), which could result in some source of drift and not solve the problem of unavailable books. This would be similar to a situation in Texas which resulted in a massive increase in the number drivers after the state increased the number of highway lanes in an attempt to compensate for the existing traffic flow, and thus negating the intended benefit of having created more highway lanes. Fortunately reading is not the same as driving on highways, and this drift would contribute to a more well-read University of Chicago campus, which would be seen as a benefit in the eyes of many.
    Furthermore, library checkouts will for the most part, avoid algorithmic confounding. Based on the sheer size and immobility of the library books, book placement impulse checkouts will always remain near constant. The library may update their website occasionally with some kind of way to encourage book checkouts, but because the library is nonprofit and the website is already fairly capable, I would not expect the library system to update the website often. One thing to be on the lookout for would be if the library began offering new services similar to uBorrow which would allow students to check out thousands of new books from other libraries virtually overnight. Fortunately, services like uBorrow and BorrowDirect are already in place and include libraries across the Midwest and much of the East Coast. It is unlikely that the University of Chicago will be joining another one of these services.
     Data from the library should also be relatively clean to work with. Different libraries may label books differently or incorrectly, or books may have slightly different titles across editions, but because of ISBNs, for the most part, nearly all the data will synchronize well. The nature of libraries is largely binary, meaning that events like call backs, checkouts, and placement on reading lists should be easily accessible from the data base without much room for confusion. 
    The library may suffer from some incompleteness (for example a book that is in high demand, but is not available anywhere), but this is not a realistic issue. Library patrons are able to offer buy requests to the library system so it would unlikely that there would be a book that is in demand and not offered at all. Likewise, if a book was in the library but not in the system, students would not be able to check it out. I do not think that incompleteness would be a problem for this dataset.
    The nature of library databases however does come with some limitations in regards to forecasting. Library databases have a lot of records about the past but naturally can’t predict what books will be published in upcoming years. However, if a new book lands on abnormally large number of people’s reading lists, this may be a good indicator of what is yet to come. Furthermore, the always on aspect of big data may be able to help nowcast sudden surges in demand. Consider last Monday when Dr. Richard Thaler just won the Nobel Prize. No one could have (assuredly) predicted this event unless they had insider knowledge from the Nobel committee which is well known for being secretive. It is also likely that the surge of demand included many students adding the book to there reading lists nearly at the same time. The library could not have forecasted the Thaler win, but with this surge in knowledge, they will be able to forecast the demand appropriately. Dr. Thaler has multiple books in the University of Chicago library system that will likely see a spike in checkouts in the weeks following the prize announcement, but will likely calm down in months ahead, and revert to normal borrowing patterns. Since the university has had other Nobel Prize winners in the past, Dr. Thaler’s event will likely follow a similar pattern to other published prize winners. The library system can then extrapolate these patterns of the past to have a good general idea of what the demand for Dr. Thaler’s books will be like.
    To conclude, forecasting which library books will be in high demand and alleviating that demand could improve the quality of life for many library patrons at the University of Chicago. Approaching book demand in a quantitative way may be be more efficient than the library’s current approach to such issues which relies on the judgement of specialist librarians to decide how many copies of each book to purchase. Because libraries typically have such well-kept databases, this project makes itself an especially a good candidate for a big data project. Furthermore, I have decided to denominate this project as “The Regenstein Method”, as homage to the library where this system was first intended to take place.
