## Evaluating Research Designs
#### Summarize the research design 
##### 1. Digital discrimination: The case of airbnb.com

The goal of the paper is to measure the racial discrimination against hosts on the online rental housing market, Airbnb.com. Specifically, the paper identifies the price differences charged by black and non-black hosts.  

In order to build up trust between the hosts and the perspective guests, Airbnb reveals some personal information of the two parties, such as its users' first names and pictures. Meanwhile, to facilitate the searching and matching procedure, Airbnb has a well-developed system to classify its renting properties based on different price factors. Listings and their features for the city of New York as of July 2012 were collected in this study. The paper uses a mass collaboration technique, human computation, to facilitate data processing. First, AMT workers were hired to rate the quality of each listing based on its photos. Second, since there is no explicit information regarding the hosts' ethnic group in their profile, AMT workers were asked to code the race of the hosts from the public profile pictures of New York City hosts. This computational method reduces the workload of the authors to deal with "dirty" data. 

Utilizing these observational data, the paper applies a matching strategy to achieve a fair comparison between different race groups. Factors the paper matches with include location, reviews, and photos. The paper first examines what factors presented by Airbnb are significantly correlated with the rental prices. The paper then constructs several regression models with a dummy variable, black host, as the major variable of interest, and price as the dependent variable, after controlling different observable characteristics.    


##### 2. Racial discrimination in the sharing economy: Evidence from a field experiment
The paper investigates the racial discrimination on Airbnb using a field experiment. The author first collected data of the listings in Airbnb in five cities: Baltimore, Dallas, Los Angeles, St. Louis and Washington, DC. Then they created 20 guest accounts, identically in all respects except for guest names, while the guest names include five distinctively African American male names, five distinctively African American female names, five distinctively white male names, and five distinctively white female names. The choice of these names are based on the frequency of names from the birth certificate of babies born from 1974 to 1979 in Massachusetts, and an additional survey verified the conformity of the classification to people's perception. Then each host was sent a request for his/her listing on a date around eight weeks later from one of the above-mentioned twenty accounts. The assignment of the guest account is entirely random. Approximately 6400 messages were sent in total, and the authors tracked the responses from the hosts over the 30 days that followed each request. All the responses were categorized into six groups, from definitive yes to definitive no, but the remaining of the paper focuses mainly on the rate of acceptance.

The paper analyzes the effect of race on the likelihood of acceptance along with different observable characteristics. In order to identify whether the effect of racial discrimination is caused by "homophily", a model controlled for the hosts' race is evaluated; while to examine if the effect of racial discrimination is heterogeneous for listings with distinctive characteristics, for example, the diversity of the neighborhood, they constructed a model including listing characteristics. 

The paper adopts several computational methods. Similar to the first paper, this paper also employed Mechanical Turk workers to categorize the race and age group from the hosts' profile pictures. A face-detection API, Face++, was also applied to categorize past guests by race, gender, and age. Furthermore, the authors developed web scrapers to collect data from Airbnb's listings. Inquiries to Airbnb hosts were sent by web browser automation tools. All these techniques greatly accelerate the data collection process and reduce the experimental period. 

#### Evaluate the effectiveness of the research design

##### 1. Digital discrimination: The case of airbnb.com

Using the observational data from a popular online marketplace, the project benefits the most from the bigness of the available data. 3752 observations were collected with each observation contains numerous price-related factors. By adopting a matching strategy, the paper provides evidence on the racial discrimination in the online marketplace: the non-black hosts charge around 12% more than black hosts. 

The large dataset enables the researchers to implement a matching strategy and make a precise estimate of the regression model. Furthermore, researchers are able to divide the data into several subgroups while remaining the number of observations in each subgroup enough to obtain valid inferences. For instance, the paper identifies that the price penalty for having a poor location is heterogeneous for black and non-black groups. This might not be achievable with small data, as we might find few observations fall into the group with a poor location for a specific race.

Another advantage of using observational data is non-reactiveness. This feature is essential for measuring discrimination, in which a survey/experiment design might get "contaminated" data: some discrimination behaviors might be masked if people are exposed to the public or monitered.  

However, on the other hand, there are some drawbacks of the observational study. First, the original data is dirty in the sense that we have to extract the race and age information from the users' profile images. Second, as the nature of digital data, the incompleteness and inaccessibility might pose threats to the validity of the results. Like stated by the author, the analysis should also consider the demand effects: the transaction price is determined by the interaction of both demand and supply. However, Airbnb is unwilling to share the demand data so the analysis can only be limited to the listing price. Moreover, when implementing the matching strategy, it is reasonable to assume that some confounding factors are not incorporated in the dataset. This will cause omitted variable bias when we estimate the coefficient of the variable of interest, which in this case, the effect of racial discrimination on listing prices. Furthermore, the data contains only listings in New York City, we might concern about the representation error if we consider the hosts in New York City cannot represent all of the hosts in Airbnb. 

Though the relationship between race and the price gap are prominent, the paper does not attempt to provide a causal interpretation of these variables. 

##### 2. Racial discrimination in the sharing economy: Evidence from a field experiment

In general, I think this paper provides a good demonstration of a digital field experiment in terms of validity, identifying the heterogeneity of treatment effect and causal mechanism. The paper provides empirical evidence of racial discrimination against the African Americans: the likelihood of being accepted for guests with distinctive African American names are 16% less than that of guests with distinctive white names. The effect persists regardless of the hosts' race, gender and experience in hosting, the prices of the listings and diversity of the neighborhood. 

The research was originally designed to fully exploit the richness of available data in Airbnb -- the authors intended to collect data from the top 20 metropolitan areas. However, the data collection process was interrupted by Airbnb so only data in five cities are acquired. Though the five cities included thousands of listings, one problem might challenge the effectiveness of the results is that, except for Dallas, which categorized as centrist, all other cities have a large proportion of the black population and are dominated by Democratic. Since the majority party's philosophy advocates the social equality, it is reasonable to assume that the data might not precisely represent the level of the racial discrimination for the entire country. Hence, we might suspect the external validity of the findings: the magnitude of the racial discrimination is likely to be underestimated for states whose majority political party is Republican. 

On the other hand, I think the paper has remarkable internal validity for the following reasons: First, as the treatment assignment (the race of a prospective guest) is randomized to hosts, we believe all other factors except for the race are the same for the treatment and control groups. Second, the authors conducted a survey to verify if the selected names comply with the people's perception in terms of their classification. The authors also checked the robustness of the names, and they found that the highest acceptance rate among the distinctive African American names is still smaller than the lowest acceptance rate of the distinctive white names. Third, the author managed to decompose the hosts based on whether they have recently accepted African American guests. While the race gap persists with hosts not having African American guests recently, it drops significantly for hosts with a history of accepting African American guests. This result reinforces the significant relationship between race and the likelihood of acceptance. 

The paper also conducted an in-depth investigation into the heterogeneous effect of race on different subgroups, taking the advantage of the enormous amount of data. The paper divided the data by 1). host's gender, 2).host's race, 3).host's age, 4).whether the host has ten plus reviews (signal for an experienced host) 5).whether the host has multiple listings, 6). the price of the listing, 7). the desirability of the listing and 8). the number of listings per census tract and 9). the diversity of the neighborhood. The discrimination remarkably persists among all these subgroups. 

However, as is discussed by the authors, one limitation of the paper is that, though the paper examined a significant and persist correlation between guests' race and the likelihood of acceptance, it fails to figure out the underlying causal mechanism: although we know it is race that drives the divergence of the acceptance rate, we are unclear about whether it is caused by discrimination or it is caused by the inferior socioeconomic status for African American.  

### Identify the value-added of conducting both research projects

Though both the two papers studied the racial discrimination on Airbnb, they adopt different angles. The first paper compares the listing price gap between black and non-black groups, the discrimination it discussed, is from the demand side: whether the perspective guests discriminate against the black hosts. Whereas, the second paper studied from the supply side, which investigates how the hosts discriminate against guests.

Meanwhile, mapping the theoretical concept "racial discrimination" to different constructs, price gap and a likelihood of acceptance, leads to somewhat similar conclusions of discrimination against the black group, we are more confident with the results: it is not caused by a tricky research design nor by using an inappropriate dataset.   

They may jointly provide strong implication for policymakers. While the brick and mortar businesses endure heavy regulation against racial discrimination, the online marketplaces, in general, remain unaffected by this administration. This is because, with the absence of face-to-face contact between buyers and sellers, most of the online marketplaces do not include unnecessary information for the transaction, which prevents discrimination from occurring in the first place. However, the results of the two studies suggest that the unique design of Airbnb that allows its users to upload profile images creates a channel to deliver the information regarding the users' gender, age, race etc. Though Airbnb does not highlight those characteristics, the indication of racial discrimination on Airbnb in both demand side and supply side should bring attention to the policymakers.  

### Apply a digital survey-based research design 

Based on the idea of the two papers, we develop a digital-based survey to learn about if there is racial discrimination for guests for the black hosts. The implementation of this survey needs the assistant of Airbnb. However, this request might be rejected by Airbnb as the expected result might be unfavorable to Airbnb. Hence, we might need to seek help from relevant authorization (probably some anti-discrimination government organizations) to negotiate with Airbnb. We want to hire survey participants from perspective guests residing in New York City when the users logged in their Airbnb account and start surfing the webpage. When explaining the purpose of the survey, the words "racial discrimination" are avoided and the users are only informed that we are to study whether the information revealed by Airbnb can facilitate decision-making process for its users. 

We collect data on around 200 listings and their host's information in New York City and employ Mechanical Turk workers to categorize the hosts' race from their profile image. For simplicity, the classification is either "black" or "non-black". Once a user enrolls into the survey, we first present them with 10 randomly selected the listings with any information regarding the host, such as first name and profile image, removed. The participants are asked to rate their intention to request the listing from a five-score scale, where five indicates strong intention to request, and one indicates no intention to request. After they complete the rating for listings without host information, the same listings are presented to the participants with the host's information revealed this time. The participants are asked to rate the intention to request again.

After the data have been collected, we can compute the difference of the ratings for listings with and without the hosts' information. Then we can divide these differences of ratings by their hosts' race group. Specifically, we will have the rating differences between the non-black group and  the black group. Then we can conduct a two-sample t procedure to test whether the differences are the same for the two groups. To prove that the racial discrimination does exist among these guests, the null hypothesis that the differences of ratings for the two race groups are the same should be rejected at a specified significance level. 

The most salient problem of conducting a survey research on this topic is that we need to avoid reactivity of the survey participants. The discrimination topic is controversial so asking questions straightforwardly is apparently inappropriate and repellent to participants. Moreover, racists might modify their behavior if they know the survey wants to measure the level of discrimination, wherein most of the cases, this modification will lead to an underestimation of the true discrimination magnitude. This phenomenon is prevailing in survey studies, but by hiding the genuine intention of the survey, we believe the effect of reactivity is limited.  

Since whether to participate the survey is voluntary, our result might have the inherited drawback of non-responsiveness for survey research projects. This will cause some representation error in our measurement. We are uncertain if there is a systematic pattern correlated with racial discrimination among individuals who voluntarily participate in our survey, and if this is the case, the result derived from the data from survey participants might not reflect the situation for the entire Airbnb users.  

#### Reference
Edelman, Benjamin G., and Michael Luca. "Digital discrimination: The case of Airbnb. com." (2014).
Edelman, Benjamin, Michael Luca, and Dan Svirsky.
 
"Racial discrimination in the sharing economy: Evidence from a field experiment." American Economic Journal: Applied Economics 9, no. 2 (2017): 1-22.

Salganik, Matthew J. Bit by bit: social research in the digital age. Princeton University Press, 2017.
