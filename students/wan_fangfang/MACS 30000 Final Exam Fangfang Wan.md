#### MACS 30000 Final Exam

#### Fangfang Wan

​	In this paper, I will examine two related papers, Edelman and Luca (2014) and Edelman, Luca and Svirsky (2017), based on the discussions of social science research using computational and digital methods in big data environment in Salganik (2017). 

​	In Edelman and Luca (2014), the authors presented an observational study using extensive computational methods. Authors collected existing information (including profile pictures, various characteristics of housing, previous reviews, etc.) of airbnb hosts in New York City in July 17, 2012, used simple regression and t-test statistical methods, and found out that on average, black hosts earn substantially less than non-black hosts, and such discrepancy still persists after controlling for charisteristics of housing, quality, location, etc. This study subtantially utilized the advantages of new research methods and tools in the digital and computational age. First, the researchers collected data using digital and computational tools on a digital platform, and the non-reactive characteristic of digital data, as stated in Salganik (2017), can ensure that we can get data of authentic human behaviors, which are critical to answering the research question. Second, the authors utilized Amazon Mechanical Turk, an online collaboration platform, to conduct several human computation tasks involved in this research. The utilization of digital and computational collaboration platform has greatly eased the researchers' work by sending out those simple but tedious work to other people, which has enhanced the working efficiency of conducting this research and answering research questions. The digital and computational methods has also greatly enabled the researchers to ask new questions. Airbnb, a new digital, online property sharing platform has enabled researchers to ask new questions that has not been asked before. Although the authors also mentioned that there are some existing paper (Zhao et al 2006, Card
et al 2008, Bertrand and Mullainathan 2004, Rubineau and Kang 2012, Scott Morton et al 2003, and Ayres and Siegelman 1995) concerning discriminations in commercial and working emvironment, the new features (such as showing the profie picture of hosts to build mutual trust between guests and hosts) of online sharing economy platforms like Airbnb, can incur new discrimination problems and bring new policy questions and implications, which were non-existent before. 

​	In Edelman, Luca and Svirsky (2017), the authors conducted a digital experiment on Airbnb. They collected data of all Airbnb listings in 5 cities, including Baltimore, Dallas, Los Angeles, St. Louis and Washington, DC in July 2015, and they included only one property per host if the host has multiple properties listed. The research includes 4 treatment groups - African American male, African American female, white male and while female. In each group, they included 5 names that typically belong to the designated group, according to Bertrand and Mullainathan (2004). Then they used those 20 names to create 20 accounts, and sent messages about 8 weeks in advance to hosts to inquire for availability of rooms during a week in September, 2015. They then recorded whether their request is accepted not not, and then conducted statistical analysis on differences in acceptance rates across racial groups. Results show that accounts of typical white names are 50% more likely to be accepted by hosts, controlling for listed price, whether the property is shared or not, host's gender and race, whether the host is experienced (with 10 or more reviews) or not, and the result still holds under other robustness checks including check for the effect of different names, etc. Nevertheless, there is an exception that African American female hosts are more likely to accept African American female guests more than any other race and gender groups, and discrepancy in accceptance rate across racial groups disappears when the authors only considered hosts that have at least 1 African American guest review in 10 most recent reviews. Such result shows that discrimination is presented only among a certain group of Airbnb hosts. In this research, the authors used computational methods like scrapers to collect data, and they built web brower automation tools to send messages to Airbnb hosts. These digital tools has greatly saved the amount of labor and time to collect such large amount of data (about 6400 responses), which can be tedious and very time-consuming if using traditional tools to collect data and send messages. Similar to Edelman and Luca (2014), the non-reactive feature of digital data allows us to gain information about real human behaviors without Hawthorne effect (Wikepedia, 2017) which can seriously jeopardize the validity of research result. Authors in this paper also used Amazon Mechanical Turk as in Edelman and Luca (2014) to conduct some human computation tasks, which has greatly enhanced the efficiency of answering the research question. As in the discussions about Edelman and Luca (2014) in the above paragraph, the benefit of computational method is not only in terms of answering questions. The new sharing economy platforms such as Airbnb in the new digital and computational era has enabled as to ask new questions, explore new problems, and find new solutions, which were impossible before. 

​	To evaluate the research design of Edelman and Luca (2014), I will first examine what we have learned from their study. The result shows that on average, black hosts earn substantially less than non-black hosts, and such discrepancy still exists (a 12% difference) after we control for factors that can affect price such as location, reviews, property quality, etc. Since this study is observational, the evaluation on its research design is largely based on the positive and negative characteristics of big data in Salganik (2017). The computational methods has brought substantial benefit to the research - as mentioned before, the non-reactive feature of digital data allows us to examine human behavior without worrying about change of behaviors under observations, which may cause bias to research result. However, there are also some limitations associated with data. One problem is non-representative. Since this research only covers Airbnb hosts in New York City, on July 17, 2012, it is limited in terms of data scope, and the dataset cannot be considered as "big data", and it does not have the "always-on" feature since its only a snapshot on July 17, 2012. Such limited data scope can cause problems. Different regions in the United States have varying cultures, and in some regions such discrimination effect might be even worse, but in some regions it might not exhibit such discrimination. In some regions where mainly black people reside, they may welcome black guests more than guests of any other races. Therefore, if other regions of the United States are included in this study, we may get different result on the aggregate level, and we may also be able to detect regional heterogeneities in terms of racial discrimination on Airbnb. Drifting might also pose problems. As the other paper, Edelman, Luca and Svirsky (2017), has pointed out, racial discrimination only occurs in a subset of Airbnb users - if we only include hosts who have at least one African American guests in the latest 10 reviews, no statistically significant racial discrimination is detected. Although in Edelman, Luca and Svirsky (2017), the authors examined hosts' behaviors, similarly, we may infer that racial discrimination only exists in a subset of guests. Since this research was done only on a single day in 2012, situations may have changed substantially since then. The composition of guests on Airbnb may have drifted significantly, and if we track the price of black hosts' properties over time, we may see different patterns, since there might be more people on Airbnb that do not exhibit racial discrimination over time, and the demand from guests may have already boosted the price of black hosts' properties. Algorithmic confounding might also pose problems, since as the authors pointed out, the properties of black hosts tend to locate in inferior locations, and when potential guests search for potential properties, those properties are listed after other properties, which may have caused guests less likely to choose properties of black hosts, and subsequently, low price comes with low demand. Moreover, the research result can be sensitive in a way that the result may cause controversy to Airbnb, which may bring unexpected economic loss to the company, and may even cause conflicts between Airbnb hosts of different races. Whether doing such a research conforms to ethics standards is questionable. 

​	As for the evaluation of Edelman, Luca and Svirsky (2017), we learned that accounts with typical white names are 50% more likely to be accepted on Airbnb than accounts with typical black names, controlling factors like the gender and race of hosts, the type the the property, the experience of the hosts, etc., while exceptions occur when we only include hosts that have at least one African American guest in the latest 10 reviews, in which the discrimination disappears, and African American female tend to host guests that are also African American female more than accounts of any other group. Since this is an experimental study, the evaluation of the effectiveness of this paper is based on the Chapter 4: Running Experiment, of Salganik (2017). First, let us examine its validity and how it deals with heterogeneity of treatment effect. This paper has done a good job on statistical, internal and construct validity. Its statistical works are done correctly, and the summary statistics tables, regression tables, figures, etc. have all contribute to answering that exact research question. The research design that created 4 groups of fake accounts, sent message to hosts and count acceptance rate has matched exactly with the theoretical construct, which aims to test the discrepancy of acceptance rate resulted only from the race of potential guests. Robustness checks have further proved the internal validity of the research result, and the discussions about the exceptions on African American female hosts and hosts that has at least 1 African American guest in the latest 10 reviews have made the result more complete and sophisticated in terms of that it grasped different patterns of different subsets of hosts and dealt with heterogeneity of treatment effect, rather than oversimplifying the situation and providing only an aggregate regression result and summary statistics. Nevertheless, if the authors can further divide hosts into groups of different educational levels, we may detect more heterogeneity of treatment effects. External validity is questionable, however, and part of the reason for this comes from the limitation of data sources. The authors mentioned that their initial intent was to collect more data and do the experiment on a broader range of hosts in more cities, but Airbnb detected the computational and digital tools that the researchers were using and blocked their tools. As Salganik (2017) mentioned in the 10 characteristics of big data, the conflicts of interests between the researchers and Airbnb (because the research result may tarnish the reputation of Airbnb and bring economic loss to the company) can cause inaccessibility of some data, or at least less data than intended, and such situation can cause non-representative problem and challenge the external validity of the research result, since as mentioned in the previous paragraph, the different cultures and racial composition in different regions in the United States can cause varying results, and expanding the time scope of the research may enable us to track the variation in hosts' attitude towards potential guest's race. Therefore, we cannot safely apply the result of this research to other parts of the United States and other time periods, so the external validity of the research result is questionable. As for the discussions of causal mechanism, the authors talked about their findings - they cannot reject either taste-based discrimination or statistical discrimination, and they talked about some exceptions about African American female hosts. Although they have some discussions about mechanism, if they can include a more substantial and specific part talking about causal mechanisms and do more sophisticated statistical analysis on testing the mechanisms using the methods mentioned in the mechanim part in Salganik (2017), this paper would be even more cogent than it is now. 

​	Let us now examine these two papers together. Each of them provides benefits that are not available from the other form of research, and if we put them both together, we may even learn something new from the interaction of these two papers. First, if we only do the observational study (Edelman and Luca, 2014), then we lose substantial information from the experimental study. The data collected from the observational study is from real-world activities. Although it can provide us with data about authentic human behaviors, the real-world data can be noisy, and there might be a lot of unobservable or undetected factors such as origincal property price for selling, which can cause biased result, although researchers have controlled for some factors that may potentially affect property price on Airbnb. However, the data collected from the experiment is much cleaner, because all accounts differ only in their names, and the causal effect is much clearer. Robustness checks also show that different names in the same group does not cause much difference, which further validates the experiment result. The experimental study provides more cogent causal conclusion than the observational study alone. However, if we only conduct experimental study, we will suffer from the loss of authentic data from the real world. Although the observational study is not able to provide cogent causal conclusion, we can learn what the real situation is from those data, which is primarily what we want to learn about. Moreover, combining both observational and experimental studies can bring unexpected benefits. First, the observational study investigated racial discrimination behaviors of Airbnb guests, while the experimental study investigated racial discrimination behaviors of hosts. Combining these two studies gives us a full picture of both supply and demand sides of Airbnb market in terms of racial discrimination. Second, using both observational and experimental studies  provides both authentic data support and causal mechanism support to answer the research questions, and makes the conclusions more persuasive if we put those two forms of studies together, since the evidence supporting the conclusuion is now more well-rounded. Third, if we can do both observational and experimental studies on both supply and demand side, the discrepancy in two forms of studies may help us isolate and figure out the reasons behind different property price for hosts of different races and different acceptance rate of potential guests of different race, because there are some factors affecting the result in observational studies, but in experimental studies those factors are mostly wiped out by the clean experimental design.

​	We can also use a digital-based survey to conduct the research and figure out the situation of racial discrimination of both demand and supply sides of Airbnb users in the United States. To figure out racial discrimination of guests when facing hosts of different races, I will design a survey and let it pop out when guests login into their accounts. I will use the way similar to "matching" methods in the "Observing behavior" chapter of Salganik (2017), but in a survey-based study scenario, and create pairs of 2 guests with similar profiles (same gender, similar age, similar Airbnb experience level, same race, same reviews level by hosts, etc.), while sending them information of 2 different potential properties with pictures of properties and profile pictures of hosts, which have the same-rating housing quality, same location, same reviews, same room type, etc, and the only difference is that one property has an African American host, and the other host is non-black, and both hosts have the same gender and similar age. I will ask the guest to rate their willingness to live in the property (0 = not willing to at all, and 5 = definitely willing to ), and record their results.  To investigate racial discrimination of hosts when facing guests of different races, I will post a similar survey to hosts. I will match a group of 4 Airbnb hosts that have same gender, similar age, similar Airbnb experience level, same race, same reviews level by guests, etc., but send them surveys with different potential guests. Those potential guests have identical gender, similar age, Airbnb experience and host reviews level, and they only differ in names, which belong to one of the four groups in Edelman, Luca and Svirsky (2017) - African American male, African American female, white male and white female, and I would like the hosts to answer the following question - "Are you willing to accept this guest to your place? Rate from 0 - 5, where 0 = definitely not willing to, and 5 = definitely willing to." Then I record their answers and compare the results. The digital-based survey can increase the number of participants involved, but there are some potential problems. The first problem is how I can let the surveys pop out on the home pages of Airbnb users. To do so, I need to collaborate with Airbnb. Since the research result may be conflict with the interest of Airbnb, I need to collaborate with external organizations to let Airbnb collaborate with us. I can first send the observational study result to federal and/or local courts, whichever is appropriate, and inform them that some researchers detected potential racial discrimination in Airbnb, and I want to do a survey to further validate our result. If there are indeed racial discrimination, then we need to take some measures to change this situation. Under the power of federal/local court, then Airbnb will collaborate with me to let the surveys pop out on the home pages of their users. I should also tell Airbnb that if there is indeed racial discrimination, and they take some measures to change this situation, it is also an opportunity for them to inform the public that they take some measures to ensure equality among diverse hosts and guests. As a big company in the industry, they undertake social obligations, which can boost the image of their company and bring potential economic benefits. Survey error might also rise from representation and measurement, as what is indicated in Salganik (2017). The representation error arises mainly from the non-response error. It is possible that people who respond are easier to communicate, and thus exhibiting less racial discrimination, and cause the result to be downward bias, or racial discrimination is correlated with responding or not for some other reasons. The measurement error arises from the fact that some people might be able to detect the goal of our survey, and change their response accordingly, which is known as "Hawthorne effect" (Wikepedia, 2017). However, since I am conducting a survey and participants are awared that they are in a survey, we cannot get rid of Hawthorne effect (Wikepedia, 2017) completely. However, I have already tried to mitigate the potential negative effect by matching users of similar characteristics as much as possible, rather than letting a single user choose between different potential hosts or guests. 

#### References:

Ayres, I., & Siegelman, P. (1995). Race and gender discrimination in bargaining for a new car. *The American Economic Review*, 304-321.	

Bertrand, M., & Mullainathan, S. (2004). Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination. *The American Economic Review*, *94*(4), 991-1013.

Card, D., Mas, A., & Rothstein, J. (2008). Tipping and the Dynamics of Segregation. *The Quarterly Journal of Economics*, *123*(1), 177-218.

Edelman, B. G., & Luca, M. (2014). Digital discrimination: The case of Airbnb. com.

Edelman, B., Luca, M., & Svirsky, D. (2017). Racial discrimination in the sharing economy: Evidence from a field experiment. *American Economic Journal: Applied Economics*, *9*(2), 1-22.

Morton, F. S., Zettelmeyer, F., & Silva-Risso, J. (2003). Consumer information and discrimination: Does the internet affect the pricing of new cars to women and minorities?. *Quantitative marketing and Economics*, *1*(1), 65-92.

Rubineau, B., & Kang, Y. (2012). Bias in white: A longitudinal natural experiment measuring changes in discrimination. *Management Science*, *58*(4), 660-677.

Salganik, M. J. (2017). *Bit by bit: social research in the digital age*. Princeton University Press.

Wikipedia. (2017, December 4). *Hawthorne effect*. Retrieved from https://en.wikipedia.org/wiki/Hawthorne_effect

Zhao, B., Ondrich, J., & Yinger, J. (2006). Why do real estate brokers continue to discriminate? Evidence from the 2000 Housing Discrimination Study. *Journal of Urban Economics*, *59*(3), 394-419.