---
title: "Assignment 3"
author: "Gabriel Velez"
date: "10/29/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##General research question: How can social media influence voting outcomes?##

##Specific research question (application to experimental project): How might different types of social media exposure affect voting patterns?##

For the previous two assignments, I proposed an observational study and a survey research project to explore the connection between social media and voting outcomes by drawing on the Colombian context.  In both cases, I had a broader research question about the influence of social media on votes, and then proposed a project that would specifically harness Twitter in order to look at the associations and motives of politically-motivated tweets in relation to Colombian voting outcomes (the 2016 plebiscite for the observational, and the 2018 presidential elections for the survey).

For an experimental project, I propose to draw on a similar underlying topic of exploration, but then to use MTurk to apply an experimental design that would target how different types of social media exposure might affect voting patterns.  By social media exposure, I refer specifically to three modes of being exposed to similar information about a candidate through social media: tweets from an official organization, tweets from an individual (i.e., “everyday citizen”), and retweets by an individual of an official political organization’s tweets. I focus on tweets and on a Colombian population of interest because it overlaps with my own research interests (and so I am specifically interested in what these associations might be for Colombian citizens). Additionally, I am envisioning this experiment as part of a larger research focus that would build on the previous two proposals and feed into future investigation. The previous two studies might (I would hypothesize) show that there are possible associations between social media and voting outcomes. This experiment could be one step toward understanding the ways different exposure might shape political opinions and voting behavior.

My proposal involves conducting an experiment on Amazon MTurk with a population restricted to Colombian users.  I recruit 300 participants to be able to group them into four experimental conditions.  Before being exposed to an experimental condition, each participant would fill out a survey on social media usage, political ideology, and favorability ratings of the currently most prominent candidates for the 2018 Colombian presidential elections (as well as basic demographic information like age, gender, SES, etc.).  Then, each would be exposed to one of four conditions in which they would be presented with information about a fake presidential candidate.  In order to make sure that differences by group (i.e., experimental condition) in political ideology did not affect results, I would set up the assignment into groups to provide a more or less even distribution.  That is, I would essentially stratify to make sure that political conservatives and political liberals were equally represented in each condition, but then randomize which of the four conditions any given conservative or liberal was assigned to.

The four conditions would begin the same way in that each would read a short “factsheet” about the candidate along with a picture of the candidate. The sheet would be written with basic information about background of candidate, demographics, and stances on key issues.  Participants would then be polled on their favorability ratings of the candidate.  Next, each of the conditions would involve a different way of receiving the same information about the candidate via a different mode.  The first would be a control group in which the information (which would involve quotes from a speech and campaign actions of the candidate) would be conveyed through a fictionalized newspaper story.  The next three would each involve the same information via a different source on Twitter: as tweets from the official campaign account, as tweets from an individual citizen’s account, or as retweets of an official campaign account by an individual (with no added commentary).  After reading through this information, each participant would be asked to rate again their opinion of the candidate, mark their agreement with the actual events/acts described in the information (i.e., on a likert scale if they approved or disapproved of these actions), and complete a short survey on whether they think the information is valid and trustworthy.  The newspaper condition would serve as a control group because the information would be provided to those participants, but not through any form of Twitter or social media.

For my analyses, I would explore if there were significant differences in changes of favorability of candidate based on how the participants were receiving the information.  Future studies could explore in greater depth these issues in many ways, such as by asking before and after exposure how favorably and how trustworthy they viewed each of those modes of conveying political information (i.e. newspaper article, official campaign tweet, etc.).  Another option would be to run a similar using Facebook (with the conditions being information on an official campaign Facebook page, on an individual’s page, and shared on an individual’s page from an official campaign page). 

As with most experiments, and any using MTurk, there are some important limits and obstacles to consider when considering the validity of this design.  The first issue is one of practicality and might possibly be one of the biggest concerns with this proposal.  A search on Google, Google Scholar, and the University of Chicago Library Search Engine revealed no studies with MTurk focusing on participants in Colombia. In fact, there is some evidence that trying to recruit samples from particular non-English speaking countries is quite difficult (Woods, et al., 2015).  The same research question and approach could be applied by creating a fake presidential candidate for, say, the United States and the experiment run with only people who are citizens of the United States. However, since this experiment is part of a larger research project, such a change would affect the applicability of the findings.  In other words, the experiment could be adapted to another context, but social media usage trends and national political culture may affect the generalizability of the such findings to Colombia.

In this particular experiment, concerns about internal validity could center around whether there are key differences within a given control group that could shape how they respond to the treatment.  As noted in Berinsky, Huber, and Lenz (2012), threats to internal validity that involve participants participating multiple times or being inattentive can be addressed through the setup on MTurk (i.e., through attention checks).  In a study such as this one, one could question whether the treatment would actually be the same based on the political ideology of the participant.  In other words, if one participant is staunchly liberal and the fictional candidate is conservative, they may have different responses to the different types of tweets about the candidate than if the candidate were liberal.  I attempt to address this in my design by first collecting pertinent data on this before assignment, and then also using an adapted stratified design in assignment.

In terms of external validity, Berinsky, Huber, and Lenz (2012) again demonstrate that using MTurk in comparison to other often-used methods does not necessarily accentuate issues related to generalizing from the experimental sample to a broader population.  Nevertheless, in this case, there are two particular concerns in relation to the sample.  One is what was noted above about the difficulties in recruiting and using a country-specific sample in a non-English speaking context.  The limited pool of possible participants may affect the external validity because there may be less diversity in the sample. It may therefore not be as effective of a sample population to generalize to the national population.  The second concern is that though participants who sign up via MTurk may be likely to also be those who use and are versed in social media like Twitter, that may not be the case.  If the participants are not active social media users and consumers (especially in relation to political topics and votes), then it is possible that their responses would not reflect the ways that social media users in Colombia differentially consume information (e.g., from official campaign tweets vs. retweets).  One possible way to attempt to address this concern would be to collect information in the beginning on levels of social media usage from the participants, and make sure that this variable is randomly distributed across the conditions.  

##References:##

Berinsky, A. J., Huber, G. A., & Lenz, G. S. (2012). Evaluating online labor markets for experimental research: Amazon. com's Mechanical Turk. *Political Analysis*, 20(3), 351-368.

Woods, A. T., Velasco, C., Levitan, C. A., Wan, X., & Spence, C. (2015). Conducting perception research over the internet: a tutorial review. *PeerJ*, 3, e1058.