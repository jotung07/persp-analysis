---
title: "HW2 - Proposing a Survey Study"
author: "Nora Nickels"
date: "10/23/2017"
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Assignment 2
## Perspectives of Computational Analysis - Fall 2017

### Research Question: Could a digitally-enhanced survey associated with STEM vs. non-STEM news topics reveal the risk for stereotype threat in a digital media domain?

Stereotype threat refers to being at risk of confirming, as a self-characteristic, a negative stereotype about one’s social group (Steele & Aronson 1995). Although a wide variety of social groups are susceptible to stereotype threat, as the conditions the produce it are ones in which any highlighted stereotype implicates one though association with a social category, one of the most widely vulnerable and highlighted social groups is that of women in math and STEM careers and majors. Situations that increase the salience of the stereotyped group, in this case, women in math, can increase vulnerability to stereotype threat, as one will be more likely to view oneself in terms of that group membership. For example, statistics about male and female performance in math or the salience of the difficulty of a math evaluation has been shown to undermine performance because of concerns about possibly confirming negative stereotypes.  

Research has shown that stereotype threat can cause underachievement on classroom exams, standardized texts, and other tasks in non-academic domains, as well as increased use of self-defeating behaviors, disengagement, and altered professional aspirations. Although these outcomes have shown clear implications for the growing field of stereotype threat research, it is crucial to examine the real-world situations that may bring salience to the social category and stereotyped group.  

Studies have shown that gender-associated stereotype threat can be easily induced simply by asking individuals to indicate their gender before a test or having a larger ratio of men to women in a testing situation. In public discourse, many public interest surveys collect demographic information immediately before inquiring about topical interest and behaviors. Research studies have show that stereotype threat has caused underachievement when exposing stereotype salience with STEM and math topics as opposed to topics in reading and the humanities. If digital survey data is susceptible to stereotype threat, we must be aware of how demographic gender data that is collected may affect subsequent answers and behaviors in the resulting digital data. 

The goal of this work would be to observe the potential of digital survey formatting to make salient the gender bias and negative stereotype of women being less capable in math and STEM fields. To assess the impact of gendered terminology on social group awareness and subsequent interest and behaviors, we plan to conduct a randomized digital opinion survey experiment. We predict that in a digital survey format, female participants who are asked to indicate their gender before expressing opinion interest in STEM vs. non-STEM articles will be less likely to show interest in STEM articles listed in digital media. We predict that females who are not asked to indicate gender will show higher amounts of interest in STEM articles. If a survey user were to become susceptible to the salience of this stereotype threat in digital surveys regarding interest in varying digital media topics, their subsequent performance, interests, and behaviors may be affected in terms of the results of digital surveys regarding digital media interest. 

This research will seek to answer the following question: could a digitally-enhanced survey associated with STEM vs. non-STEM topics reveal the risk for stereotype threat in a digital media domain? That is, does survey research that asks for gender demographic information and therefore acts as a salient trigger of stereotype groups have a subsequent effect on user interests and opinion answers?  

The research design here would involve utilizing a paid-incentive Mechanical Turk survey that subjectively asks about interest and likelihood to read digital media news articles that surround STEM vs. non-STEM topics. Half of male participants and half of female participants would randomly receive a gender identification question after a variety of other demographics questions (political self-identification, educational attainment, age, ethnicity, career, and educational major / interests), while the other half would not be asked to identify gender. All participants would then answer a series of questions regarding interest in a counter-balanced list of Internet media articles that either involve STEM topics or non-STEM topics. Participants would be asked to rank these article titles on interest, likelihood to click further, and likelihood to actually read. Logistic regressions predicting the amount of interest and likelihood of STEM and non-STEM topical articles will be conducted, with the existence of a worded demographics gender question followed as the independent variable.  

This survey is digitally-enhanced for several reasons. Firstly, utilizing a program like Mechanical Turk allows us to reach a wider, broader Internet audience than the use of paper surveys or phone surveys. This will seek to reach wider and broader audiences, more quickly. Second, using wording of actual digital media articles will create a more realistic experience of Internet news browsing and also of a digital stereotype trigger, which both younger students and adults are more likely to run into as computer usage increases. Third, asking questions about both likelihood to click an article and likelihood to actually read will create a more realistic digitally enhanced scenario. This behavioral scenario is more common as computer and digital media usage increases; participants can express “likes” and interest without actually reading the material in full. This enriched asking adds to the observed data that we collect by creating a more realistic digital behavior scenario.  

This research design differs from one that uses digital observational data in that it has the ability to collect data that show direct responses (i.e., preferences in digital media articles) to a randomized wording *experiment* in survey format. That is, we see direct outcomes of user behavior to our manipulation as opposed to simply observing gendered terminology that already exists in digital media domain. This design results in direct benefits over an observational study. It combines the ability to create a digital, real-world scenario while actually viewing subsequent interest and behaviors. In terms of the former, this digital scenario of online media articles provides a more realistic scenario of stereotype triggers than an artificial laboratory study. In terms of the latter point, collecting digital observation data is a simple quantification of gendered terminology; with an experimental manipulation of digital survey data, we have the ability to view direct behavioral outcomes of the presence or lack thereof of a salient gender stereotype trigger in digital survey data.  

There are multiple potential sources of error in our research design. First, although an M-Turk sample would provide a more heterogeneous sample than an in-lab research study, it is not completely representative of the American public. It will be bias in that it will include individuals who are more digitally savvy than individuals who would be sought after for phone and paper surveys, and therefore may be bias towards individuals who are younger or wealthier. Therefore, the observed percentages will not be the most reliable estimates of population differences. This will result in representation error. To rectify this, we can take a pilot poll of the data after ten percent of our targeted data collection is complete, observe the collected demographics, and then send the M-Turk link to individuals who fit the demographics for which our pilot data is lacking (e.g., older individuals, individuals outside of academia). This may help us create a more accurate frame population as we seek to continue to gather our sample.  

Another source of error is that involving the construct validity of our survey; that is, there may be error in how we make inferences in answering our question of the salience of stereotype threat in survey data. For example, individuals who work in STEM topics may be more interested in clicking on and reading STEM articles, despite being a male or a female, than individuals who do not work in STEM. Therefore, our inferences in these individuals not being negatively affected by stereotype threat may have nothing to do with a trigger of a gender question, but instead on genuine interests for those individuals. In particular, a digital domain is more private than making behavioral choices in front of other members of the stereotyped or non-stereotyped group, and this may help individuals to not be negatively affected by salience in demographics trigger questions. To avoid this measurement error, we can seek to control for major, academic interest, and career positions using other demographics questions for our collected data. We can account for these factors in our statistical analysis to try to separate this inferential error.  

In conclusion, understanding the effects of gender salience in digital media preferences of STEM vs. non-STEM material would help to mitigate the effects of subtle stereotypical associating messages in survey design data, thus reducing stereotype threats effects on interest and behavior.


