## Mass Collaboration HW
## Weiwei Zheng

### **Part** 1
##### Problem 1
My user name is tesan16, under weiweizheng16@gmail.com
##### Problem 2
The Text Normalization Challenge interests me most. Competitors should come up with algorithms to normalize textual data by differentiating nuances in speech and written languages, transforming non-standard language expression and extracting the correct meaning from the syntax.

For human beings, it’s difficult to deal with a plethora of textual data. A machine benefits human by extracting keywords from textual database and making statistical inferences on syntax possible, but in the digital era, patterns of human interaction have been enriched and semiotic meaning in text becomes much more diverse than the analog age. Texts are now everywhere, which provides social scientists with rich resources to study human society, but for people, studying every kinds of transformation happening in semantic layer of texts is impossible. Algorithms developed currently cannot catch up with changes happening in people’s textual communication. Hence, initiating an open-call to recruit experts in language processing to co-create powerful algorithms which can normalize “weird” and messy texts in an analyzable way does a lot help to social scientists interested in media discourse analysis. 

To make a submission, we need to write codes to normalize the informally stated text sample in a readable way and extract the meaning of the sample. The algorithm should not only consider the grammar mistakes in the sentences but should also deal with non-standard formats of languages such as abbreviations, numbers or currency expressions and other semantically constrained text tokens.    

##### Problem 3
The dataset is TMDB (The Movie Database) 5,000 Movie Database

### **Part 2**
In the article *Why Elites Love Authentic Lowbrow Culture: Overcoming High-status Denigration with Outsider Art*, the authors conducted an experiment to test the hypothesis that elite people tend to consume lowbrow culture to compensate their high-status insecurity. This experiment is digital-enhanced, for respondents were recruited from the online AmazonMturk. However, as for the treatment distribution part, there’s still room for improvement. 

During the experiment, after researchers manipulated respondents to make them feel as high/low-status and authenticity-secure/insecure, respondents were asked their preference to different kinds of paintings categorized as high/low-brow high/low-authenticity painting to see the differences between different groups. As I see, pitfalls might occur if two conditions are not satisfied in this context. First, there should be sharp contrast between paintings in different categories, otherwise, respondents’ preference on different paintings cannot be a valid measurement of their differences in tastes. Second, paintings themselves should be representative of lowbrow/highbrow with low/high-authenticity. If the categorization of paintings are highly contradictory, internal validity will be violated. 

Cultural analysis in sociology continues to be hampered by coarse-grained concepts of different modes of culture. In this sense, the abovementioned section can be improved by designing a mass collaboration. Researchers could have aggregate a large amount of paintings and designed an online platform to let Internet users to classify the paintings after giving them a brief instruction about what is high/low-brow, and what is authenticity in the cultural sense. Before letting the participants to do the classifying, researchers can design simple tests on their understanding of the concepts and only let people who have passed the tests to do the task. 

The merit of this modification are as follow: First, researchers can pool a much greater sample of paintings in the very beginning to pick up the most representative ones accepted by most participants to do the experiment. Second, thanks to the strength of redundancy by letting different people categorize the same set of paintings, researchers can minimize the error in categorization. Using statistical methods, researchers can select the paintings with least margin of errors to test respondents’ preference. In this sense, the results might have been more suitable to the taste of majority in the society.

Cultural studies are concerned about tastes of different people, which are quite hard to measure and involve much ambiguity on individual preference, even for experts in the field. So why not simply let the targets (general population) themselves classify what they think is lowbrow or highbrow, and with high-authenticity and low-authenticity. 

##### References
Hahl, O., Zuckerman, E. W., & Kim, M. (2017). *Why Elites Love Authentic Lowbrow Culture: Overcoming High-Status Denigration with Outsider Art*. American Sociological Review, 0003122417710642.

### **Part 3**
##### Compare and contrast

**InfluenzaNet** is an influenza-like disease monitoring system based on voluntary self-report by internet users. Participants were asked to periodically report their status related to influenza and conditions of people around them by filling out short questionnaire distributed online. Information  including symptoms, health-related activities and demographic information is collected to estimate the outbreak and general trend of influenza by analyzing the raw data through statistical inference. 

This quasi-mass collaboration method doesn’t take much expense, but some costs like distributing news-letters to remind respondents to fill in the survey and maintaining the online data-collecting system are necessary. 

However, InfluenzaNet has some evident pitfalls which restrict its ability to independently fulfil the predicting task. First, the system cannot avoid systematic measurement error. Though researchers preclude people only responding once they don’t know whether an unobservable systematic relation between dropping out of the program and certain unknown demographic character of the group. This might violate external validity in which estimates cannot be generalized to greater population. Second, the survey precludes some social groups who might not get Internet access from the very beginning, such as the old, illiterate, adolescents, and disabled, if no people around them report their conditions. As a result the estimate cannot guarantee external validity. Third, it’s hard to define what specific symptoms are related to influenza. Influenza keeps transforming along the process of infection resulting in unknown derivative unless close examination after a period of outbreak. This leads to potential construct validity of the inquiry.  

**Google flu forecasting** estimates the outbreak of influenza by monitoring relevant searches online. Several parameters, keywords being searched, are deemed as effective predictors of the phenomenon. Though causal relationships between some searches and influenza are not clear, it’s regarded as a powerful now-casting technique compared with the traditional influenza tracking system.

This method is the cheapest one among the three, which costs nothing to collect data, neither maintaining the websites nor rewarding the respondents. All we need is just smart and talented programmers to design a powerful model to predict the current trend at one time. 

The method still has some drawbacks in not clarifying the causal relations between predictor and predicted variables. As mentioned before, influenza transforms over time. If the internal mechanism influenza-related human searching behavior stays uncertain, the modesl used might lose power after certain period. Moreover, as InfluenzaNet, Google flu forecasting also precludes people without access to the Internet. But Given that searching behavior is a relatively autonomous behavior, dropping out rate is not a problem of this method. 

The **traditional influenza tracking system** estimates the severity of influenza by measuring the frequency of physicians-going in different communities. Each time an influenza-patient goes to the clinic the doctor takes the record and reports it to the health department. What the system measures is exactly infection of the influenza, but the estimate of overall conditions comes out only in fixed time during certain period. This method is the most expensive one among the three, not only fees for physicians and nurses are needed but that to run the medical system which distributes results and organizes logistics affairs is indispensable to support this public welfare system. 

Similarly, the traditional monitoring system also suffers evident weakness. First of all, it lacks promptness. The results of analysis cannot produce effective estimate of the current situation but only depicts conditions in the past, which might lead to time lag and unsuitable solutions social sectors are going to implement remedies after unexpected outbreak of influenza. In addition, as the above two methods, the traditional one also precludes certain populations and only observes behavior of those with health insurance. 

##### Swine flu outbreak
In unsettled time of swine flu outbreak, several problems might happen on each of the three systems. For **InfluenzaNet**, in the early time of epidemic, people might be unsure about what are the symptoms of swine flu, so it's hard to design the questionnaire, and people might report many unrelated data to researchers, leading to confounding errors. Besides, the system is based on people’s web browsing habit to collect the data. The measured data might preclude some groups of people without access or intention to browse their phone often to fill in the frequent allocated questionnaires. Regarding **Google flu** searching system, people might have different searches each time different kinds of flu outbreaks. The unknown causality between searching behavior and outbreak of flu must cause unreliable prediction of flu trend when new condition happens and it also takes much work to filter what the most related keyword searching are for specific type of flu. In terms of the **traditional method**, again, it neglects the social underclass without health care provisions or access to physicians, who are the ones most easily getting infected by flu. Researchers might fail to observe the outbreak in the early stage. 




