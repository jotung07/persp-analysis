Name: Sumer S. Vaid 

Assignment #3

**Clearly Stated Research Question**

Researchers have categorized all non-vaccinators into four organized categories: those that are complacent (Complacent), those that cite convenience as a barrier (Convenience), those that have a distorted perception of vaccinations (Confidence) and those who calculate the costs and benefits of vaccination and favor not vaccinating after this process (Calculating) [1]. Perhaps, the reason general strategies for increasing vaccination rates has failed because they employ a single strategy in convincing non-vaccinators, who vary in types, and therefore have different sensitivities to this generalized strategy.  This research study aims to investigate systematically varied strategies in convincing these four different kinds of people about the effectiveness of vaccines. 

**Clearly Stated Research Plan**

The overall study design resembles that of Kevin Munger (2017) [2], in which “bot” Twitter accounts are employed to recruit and administer interventions that reduce social bias to certain groups of individuals. 

*Recruitment (Digital)* 

We will use Twitter data to classify a random sample of (non-vaccine) users as falling in one of the four categories described previously, using the history of tweets. Additionally, we will have a control batch sampled from those twitter users who have expressed desire to vaccinate. The methodology to identify and target Twitter users belonging to one of the four category of vaccinators will be borrowed and modified from  Munger (2017)’s method of identifying racist users. The four different types of vaccinators, given their semantic differences, use different kinds of tweet-words to justify their stance against vaccinations, and can therefore be grouped using the same methodology as Munger (2017). 

*Randomized (Digital)*

The subjects will consist of randomly sampled Twitter users. 

*Intervene (Digital)*

Bot accounts on Twitter will be used to offer different types of “sanctions” to different types of non-vaccinators, with the aim of measuring the interaction between strategy type, non-vaccinator type and resulting change in beliefs. There will be one factor (independent variable) in the experiment with six levels: four levels correspond to four strategies that are specifically tailored to each of the non-vaccinator type, a conventional vaccination encouragement announcement and a control text strategy that is orthogonal to the semantics of vaccination. Each strategy will have a bank of 100 tweets that will be posted on the bot account every 2 days for a total of 50 days. The total pool of participants will be divided into 12 groups, which will be divided into 2 clusters (each cluster consisting of 6 groups of n participants). One cluster is the experimental cluster. Participants in the experimental cluster will receive bot-tweets that are designed to resist their specific anti-vaccination thinking, as divided by types. The remaining two groups in the experimental cluster will receive a control tweet prescription and a domain-general vaccine encouragement tweet.  The second cluster is the control cluster. Participants in the control cluster will receive bot-tweets that are from a different strategy pool than their own “match”. The remaining two groups in the control cluster will receive a control tweet prescription and a domain-general vaccine encouragement tweet. The dependent variable will be operationalized through measuring the semantics of tweets after complete administration of  bot tweets. The post-treatments tweets from non-vaccinators will be analyzed for indications of changes in vaccination attitude.

To ensure that our treatment tweets capture the different dimensions of different types of anti-vaccinators, we will rate all the treatment tweets on all relevant dimensions of anti-vaccinators. Then we will group together tweets using clustering techniques that have similar dimension-specific ratings to create four different pools of anti-vaccinator specific “cure” tweets. The tweets will be rated in a 30-second experiment by 5000 participants recruited through Amazon Mturk to ensure their validity as resisting one of the four types of vaccinators or being perceived as a domain general vaccination encouragement tweet. 

*Measure (Digital)*

The dependent variable of our experiment will be the number of anti-vaccine tweets created in a month by any one of our participants. We will utilize machine learning approaches to determine if a tweet was anti-vaccine or not. 

We will conduct statistical tests to determine if the mean of the treatment “match” group differs significantly from the treatment “mismatch” group.  We expect that there will be a significant difference in attitudes between match and mismatch group participants as compared to match and control-paired participants, and match and non-vaccine tweet participants. 
The number of followers that each bot account has will be roughly equal for all bots as will antecedents of the true personality of the bot. The true personality of the bot will be “set” to that of a high-status white male to maximize impact. 

***Assessment of Experimental Design***

**Heterogeneity of Experimental Effects **

The twitter data of our users can be used to infer information relating to their political affiliation [3] and socioeconomic status [4]. We will use this additional information to measure the treatment effects within ideological and financial sub-groups in each of our 4 experimental groups. To measure potential effects originating from impression formation of the twitter bots, we will analyze the heterogeneity of experimental effects across ethnic sub-groups too. The ethnicity of our participants will be inferred from their twitter data [5]. As the true personality of all twitter bots in our experiment will be caucasian, we will analyze how the treatment effect fluctuates across caucasian participants and non-caucasian participants, in each of the experimental groups. 

**Causal Mechanisms **

We determine causal connections using three statistical comparisons. First, we compare the treatment group with a different treatment group. Then we compare a treatment group with a non treatment group. Finally, we compare the effect of treating impaired populations with our treatment versus treating a healthy populating with our treatment. Hence, any causal claims are shielded against both type 1 and type 2 errors. Second, we eliminate the possibility that confounding variables propagate the examined causality, as we are comparing treatment groups to other treatment groups, non-treatment groups and non-impaired groups. 

**External and Internal Validity**
 
There is high internal validity in our experiment as it employs a treatment-based design on Twitter.  Our treatment type-specific tweets operationalize the intended anti-vaccinator concept as we only select those tweets are externally rated highly on the dimensions we seek to operationalize. For instance, a “Confident” anti-vaccinator tweet bot will only send those tweets that we have previously verified as tackling specifically the confidence of the anti-vaccinator. We assume, however, that shifts in vaccination attitudes are reflected in the post-treatment tweets of our participants, which is a significant assumption to make. Our experiment will not be able to measure instances of vaccination-position changes that occur entirely offline. This reduces the internal validity of our experiment, as we seek to ultimately test the efficacy of our approach on cumulative vaccination attitudes, not just those that are expressed online. As discussed below, this is primarily an issue of diluted construct validity that also reduces the internal validity of the experiment. However, our inclusion of a control treatment group and non-impaired treatment group allow us to make comparisons that can eliminate potentially confounds, boosting the internal validity of our experiment.   Our experiment has high external validity as we sample participants randomly from a social media website that possesses a mostly diverse crowd that is generally representative of the American public. However, some studies suggest that Twitter contains more Democrats as compared to Republicans [6]. This reduces the external validity of our study as our study sample does not represent the current division of political affiliation in the United States, which fluctuates across time [7
].  

**Construct and Statistical Validity**

We will compare treatment groups with control groups by subtracting their post-treatment mean attitudes and by observing if this difference is sufficiently different from zero  We will use the same methodology to analyze if pre-treatment and post-treatment mean attitudes vary across the treatment groups. We will use a two-sample t-test to assess if the difference of means is significant, which is a widely practiced approach in the field. As our experimental design meets all the assumptions of a two-sample t-test, we can conclude that there is high statistical validity in our experiment. We claim to be measuring post-bot treatment attitudes of non-vaccinators, but we are really only measuring post-bot treatment attitudes of non-vaccinators that are expressed online. However, by sampling active Twitter users, we can make the assumption that particularly vocal anti-vaccinators’ will reflect their change of position in their online Twitter activity. Moreover, we are not only examining complete changes in position concerning vaccinations, simply a reduction of anti-vaccination attitude. While the former might not make it online because of egotistic reasons, the latter will be examinable from one’s Twitter feed. 

**Digitally Enhanced Evaluation of the Experiment**

This experiment uses several unique benefits of digital experiments. First, we can sample across a large user-base to identify our four populations of interest. Second, we can administer systematic and group-specific treatments to them using the same digital platform. Third, we can examine the effects of our treatment using the same digital platform, over a period of 2 months. Given this experiment’s reliance on digital methods, it would be near-impossible to replicate in analog terms. There is an ethical aspect of our experiment: our control treatment group participants are vaccinators whom we are choosing to be ignorant about. As such, if ignorance can be equated to facilitation, we are facilitating an unhealthy activity by not opposing it for a certain group of individuals. Furthermore, we are unable to obtain informed consent from our participants, presumably because they would not want to actively participate in an experiment dissenting against their current ideology. However, as the ultimate goal of our experiment is well-intentioned, these relatively smaller ethical drawbacks can be ignored. If customized Twitter bot strategies can indeed be employed to reduce unhealthy behavior, then knowing and applying this technique can yield fruitful social returns. 

References

[1]- http://journals.sagepub.com/doi/abs/10.1177/2372732215600716"

[2]- 
https://link-springer-com.proxy.uchicago.edu/article/10.1007%2Fs11109-016-9373-5

[3]- http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0137422&type=printable

[4] - http://www.lampos.net/inferring-socioeconomic-demographics-twitter

[5]- http://cs.iit.edu/~culotta/pubs/culotta15predicting.pdf 

[6] - https://bits.blogs.nytimes.com/2014/04/30/the-political-preferences-of-social-media-sites/?_r=0 

[7] - http://news.gallup.com/poll/15370/party-affiliation.aspx 
