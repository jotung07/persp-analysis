
# Final Assignment
### Siyi Fan

## Question1 Summarize the research design and explain how the research design leverages computational methods to ask and answer a question.

In the paper Digital Discrimination: The Case of Airbnb.com, the researchers investigated the extent of racial discrimination against hosts on the Airbnb.com, specifically on the price gaps between black and non-black hosts. 
First, the researchers constructed a new dataset consisting of a snapshot of listings on Airbnb for the city of New York. The listings include: the price that the host is asking, the characteristics of the host, and the characteristics of the properties. In addition to the listings, information also includes: the number of guest reviews and the average rating for each host characteristic. Then, the researchers recruited participants through MTurk to rate the quality of each listing on a seven-point scale. At the same time, some participants were also recruited by MTurk to code the race of the hosts whose pictures were downloaded from public profile on the Airbnb by the researchers. Finally, they analyzed data by controlling factors like location, reviews, and photos and found out the gap in rents received by black and non-black hosts. 

The research design in this paper to leverage computational methods is to use mass collaboration through MTurk. Specifically, one group of workers on MTurk rated the quality of each listing in order to control the listing properties, the other group of participants coded the race of the hosts, which is critical for testing the price gaps between black and non-black hosts. This split-apply-combine methodology improves the research outcome by splitting the tasks into rating and coding part, allowing subjects to take them independent, and then aggregating back to the total dataset. 

In the paper Racial Discrimination in the Sharing Economy, the researchers investigated the existence of racial discrimination against guests on Airbnb by conducting a field experiment. First, they collected data on all listings in five cities, covering the price, listing characteristics (number of bedrooms, bathrooms, location, reviews, etc.) and host characteristics (host reviews, pictures). Then, they recruited participants on MTurk to assess each host image for race, gender, and age. Through this process, hosts were categorized by race, gender, and age. At the same time, the researchers created guest accounts differ by name, either African American name or white name and differ by gender, either male or female. From these four treatments on guest accounts, the researchers sent messages to hosts which were randomly assigned to guest accounts. After that, they tracked host responses over the 30 days followed each request and coded each response into 5 categories. Finally, the researchers collected all data using scrapers and sent inquiries to Airbnb hosts using web browser automation tools. 

The research design in this paper to leverage computational methods is to use MTurk, Face++, and scrapers. The researchers used split-apply-combine method to assess race, gender, and age, while in the meantime, they took double check by inferring more subjects’ opinions to ensure the validity of picture coding. In this way, hosts could be categorized by different characteristics. Face+ is a face detection API, which was used in this paper to categorize past guests by race, gender, and age, so that to examine relationships between a host’ prior experience and their discrimination behaviors. Finally, the researchers collected all data by using scrapers to get profile pictures and sent inquiries to Airbnb hosts by using web browser automation. This computational method provides opportunities to communicate with hosts in a more efficient way and finally build a big database. Finally, the researchers created each listing to link to census demographic data to assess the relationship between neighborhood demographics and discrimination, which allows for the heterogeneity of hosts in various neighborhoods.

## Question2 Evaluate the effectiveness of each paper's research design independently.

I will evaluate the effectiveness from five aspects: characteristics of big data, validity, heterogeneity of treatment effects, causal mechanisms, and ethics.  

### Big data – Big
For the paper Digital Discrimination: The Case of Airbnb.com, the researchers built an online dataset and recruited participants to rate the quality of each listing. These big data sources including lots of characteristics and choices could help to provide more information to each subject. It could also help researchers to explore more results. For example: the researchers even found out the interactions between the number of bedrooms and access to the whole apartment which is beyond the initial purpose of this study. 
For the paper Racial Discrimination in the Sharing Economy, the researchers collected 6400 listings on Airbnb across five cities. This big data source allows researchers to examine the interaction between hosts’ responses and the characteristics of their properties. Also, the big data source is useful to make estimates for specific subgroups. In this study, the researchers could categorize the hosts into subgroups based on their profiles, ratings, and listing characteristics so that they could examine if those factors have an impact on their responses to the guests.  

### Big data – Always-on
In the paper Digital Discrimination: The Case of Airbnb.com, we cannot tell the obvious advantages of always-on data, but I would suggest they could track prices over time and further observe its relationship with race. But for the paper Racial Discrimination in the Sharing Economy, always-on data collection enables researchers to produce real-time measurements. By tracking host responses over 30 days, the researchers could troubleshoot their categorizing ways on hosts’ responses. Specifically, the initial categorizations may use subtle distinctions between possible responses, but after collecting always-on responses, they restricted their attention on the simplest responses. 

### Big data – Non-reactive
For the paper Racial Discrimination in the Sharing Economy, hosts were not aware that their choices were being captured so that they could make real choices (responses) without changing their behaviors in order to meet the social desirability. Particularly for the issue of racism, big data allows researchers to study subjects’ behaviors that are not amendable to accurate measurement previously. For the paper Digital Discrimination: The Case of Airbnb.com, participants on the MTurk were free to make any choices without being observed, so they won’t change their original behaviors. Therefore, it allows researchers to observe if discrimination does exist on Airbnb. 

### Big data – Incomplete
For both papers, the researchers didn’t identity distinct types of discrimination. One is taste-based discrimination, which is simply based on personal preference. The other one is statistical discrimination, which is grounded in inference of information provided. However, in the paper Racial Discrimination in the Sharing Economy suggests a mixed mechanism. Specifically, they found discrimination is not sensitive to a measure of proximity between the host and guest which is against taste-based discrimination. At the same time, they also found that hosts who had an African American guest in the past have less discrimination than other hosts, which is in tension with statistical discrimination. Therefore, even if it is hard to test models of discrimination, researchers could still merge multiple data to illustrate the results. 

### Big data – Inaccessible
For the paper Digital Discrimination: The Case of Airbnb.com, Airbnb refused to share data on consumer demand, which made the analysis of demand effects unavailable. It is also a system drift problem brought by Big data, because Airbnb changed the system itself to block this long-term study. For the paper Racial Discrimination in the Sharing Economy, the researchers stopped data collection after five cities because Airbnb blocked their automated tools to communicate with hosts and their requirements were declined by Airbnb. Therefore, some sensitive sources of big data restricted to the company Airbnb are inaccessible to researchers. 

### Big data – Non-representative
In the paper Racial Discrimination in the Sharing Economy, the researchers avoided this problem by using multiple checks. They hired two participants on MTurk to assess each image, and if the workers disagreed on race or gender, they hired a third to settle the dispute or manually coded the picture. This method could attenuate the personal differences. However, for the paper Digital Discrimination: The Case of Airbnb.com, participants recruited on MTurk were a random sample from any specific population. For example, older generation has less knowledge on Airbnb than younger generation, so they may mainly focus on the hosts’ characteristics, while the young people may care more about the experiences of travelling other than staying at a home, living with others, so the characteristics of properties are more important to them. 

### Big data – Dirty
In the paper Digital Discrimination: The Case of Airbnb.com, the researchers avoided this problem by only focusing on the price offered by hosts. For the paper Racial Discrimination in the Sharing Economy, the researchers changed their initial categorizations on hosts’ responses, restricting to the simplest answers – “Yes” and “No”. Because the purpose of this study focuses on differences in host responses, and the results showed that nonresponses or intermediate responses have no relationship with race. 

### Validity
For the paper Digital Discrimination: The Case of Airbnb.com, the external validity is doubtful. The authors only collected pictures of New York city landlords on Airbnb as of July 17, which may not be able to generalize to other cities at different time. Internal validity is also questionable because of its non-representative data collection. As I mentioned above, the treatment should be delivered to those who are familiar with Airbnb or other similar platforms. Additionally, since the researchers didn’t identity distinct types of discrimination, it is hard to define what behaviors show discrimination and what discrimination is. In this way, I have to doubt the experiment and the theoretical constructs may be less tight and its construct validity is also questionable. 
For the paper Racial Discrimination in the Sharing Economy, it has strong external validity and internal validity. First, the researchers inquired about 6400 listings on Airbnb across five cities, which is large enough to generalize to other situations, even if it is still questionable to say discrimination also exists on other online platforms. In terms of internal validity, the researchers validated the name list by conducting a survey in which they asked subjects to categorize each name as white or African American in order to make sure the names can reflect race.  

### Heterogeneity of treatment effects
The same treatment can have different effects on different people. In the paper Racial Discrimination in the Sharing Economy, the authors set subgroups of hosts based on their personal characteristics and characteristics of properties. Heterogeneity of hosts was also the main finding in this study and researchers used those factors and interactions between them to explore the discrimination phenomenon on Airbnb.  

### Causal mechanisms
For the paper Digital Discrimination: The Case of Airbnb.com, the researchers conducted an observational study which is not sufficient to suggest the causal relationship between hosts’ race and offered price. For example: is there any possibility that most white hosts compared to black hosts are good at managing a “home inn”? 
For the paper Racial Discrimination in the Sharing Economy, although the researchers didn’t reveal the specific causal mechanism, they did a good job on designing multiple treatment groups to look at the interaction effect. Specifically, they set four groups based on the perceived race and gender of the test guest accounts and tested if responses rate got influenced by characteristics of each treatment group. 

### Ethics
For the paper Digital Discrimination: The Case of Airbnb.com, the participants knew that they were joining a study. But for the Racial Discrimination in the Sharing Economy, the hosts had no idea that they were included in a project, because they didn’t get any informed consent or debrief after the study. Even if this study results may improve the online environment, but I don’t think it strikes the right ethical balance. The reason is that the authors didn’t take any further steps to reduce the probability of adverse event, but instead, just enrolled hosts in an experiment and used their data without their awareness, which violated the principle of Respect for persons (Salganik). 

## Question3 Identify the value-added of conducting both research projects. 

Observational studies involve the direct observation rather than manipulation of individuals in the natural setting. So it can be made in real life situations, providing access to what people say and behave. Race is a sensitive topic, so people may not be willing to reveal their real attitudes to it. In the paper Digital Discrimination: The Case of Airbnb.com, observation method then allows researchers to collect the data they want. However, there are mainly two drawbacks. First, the measurement of key variables also introduces potential confounding variables, due to lack of control, that is, there are alternative explanations other than race for the offered price gap. 
Second, the internal validity is doubtful. As mentioned above, the observational study conducted in this paper didn’t use randomization so that it loses internal validity as well as construct validity. In this way, it is difficult to induce the causal relationship between race and offered price. The external validity is still questionable because of its limited choice on cities and dates. Furthermore, internal validity is a prerequisite for external validity, that is, the study must prove that the outcomes are caused by the independent variables before one can generalize the results to other situations. Therefore, the validity is relatively low for this paper.  

A field experiment to some extent is also conducted in a natural environment, but at the same time controls the independent variables, so participants are still unaware that they are being studied. Natural environment and study control contribute to both high external and internal validity, and allowing researchers to induce the causal relationships. However, it is difficult to obtain fully informed consent from participants, which may suffer from the ethical problem. For the paper Racial Discrimination in the Sharing Economy, the researchers took control on the independent variables by creating treatment groups and picking their profile names. They also used randomization to assign hosts to guests and multiple times of check to improve the precision of the experiment. This study also covered five cities and thousands of hosts, which improves it external validity. Furthermore, the researchers suggested a mixed discrimination mechanism based on the big data collected, even if they didn’t directly conduct test to examine the mechanism behind discrimination. The downside is that the hosts were included in this study without awareness, which raised an ethical issue. 

It seems like the research design of Discrimination in the Sharing Economy is more persuasive than the other one, but by combining two methods, we may get more sophisticated results on online discrimination. The study of Discrimination in the Sharing Economy addresses on the discrimination for hosts, while the study of Digital Discrimination: The Case of Airbnb.com targets on the discrimination of guests. Therefore, supply and demand discrimination on Airbnb may help us to further analyze the impact of racial background in user behaviors on Airbnb and finally contribute to future studies on discrimination phenomenon in the whole online platform, and hopefully, capture the attention from related departments to address on the ethical issues online. Besides, observational study could reflect many phenomena which inspire researchers to control more variables in the field study.  

## Question4 Consider how you could apply a digital survey-based research design to the primary question of interest from these two papers.

The purposes of two papers are to investigate if discrimination exists on Airbnb for supply (host) and demand (guest) sides. The same result could also be realized by applying a digital survey-based research design. 
First, I will create two types of surveys, one for demand side (host), and the other one for supply side (host). Subjects will be randomly assigned to one survey.

For the demand side, participants recruited on MTurk will image themselves as Airbnb guests. At the start of the survey, a scenario will be presented to the first group of participants: “Image you are visiting a city as a guest. There are several Airbnb hosts available for you to choose. How would you rate each host and how much would you pay for it?” After that, the subjects will make choice from multiple fake Airbnb hosts. When they click in the housing image presented on the survey, they will see fake hosts profiles and the characteristics of their properties. I will create the listing with the same criteria like the first paper suggests, including: the location of the house, previous reviews, hosts profiles, etc. 

For the supply side, the other group of participants also recruited on MTurk will image themselves as Airbnb hosts. I will make sure the size of two groups is the same. At the start of the survey, a scenario will be presented to the second group of participants: “Image you are one Airbnb host. There are several guests sending you request. Which one you would give a positive respond? Then, participants could read each message with sender’s name (I will make sure the requirements of each message are the same). I will use the name exactly the same like the second paper suggests. The only difference is that each participant will be randomly assigned two African American females’ names, two African American males’ names, two White females’ names, and two White males’ names, that is, they need to read and evaluate eight messages in total. 

There are several concerns. The first one is that the behaviors under imaging as a guest or host are not consistent with their real behavior in life. In order to overcome this drawback, I will follow the second paper by linking survey data with observational data accessible on Airbnb. The second concern is that participants need to read and rate multiple listings, which may get them bored. Therefore, I will motivate subjects by providing gift cards or money. Since this research expands the reputation of Airbnb, I may contact Airbnb for offering discount on participants’ next visiting. The third issue is about participants’ racial background. Addressing on this issue, I will take stratified sampling and weigh the result based on those participants providing their racial background. The fourth issue involves the ethical problem. The purpose of this research is to investigate discrimination online which is sensitive and easily arouse social desirability effect. To solve this drawback, I will take a risk/benefit analysis by turning to experts, Airbnb company and related departments and debrief all participants after the survey. 

## Reference
Salganik, Matthew J. 2017. Bit by Bit: Social Research in the Digital Age. Princeton, NJ: Princeton University Press. Open review edition.
